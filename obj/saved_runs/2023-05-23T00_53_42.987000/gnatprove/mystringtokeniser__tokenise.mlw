module Standard__integer
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  
  type integer = <range -2147483648 2147483647>
  
  val function first : int
    ensures { result = ((- 2147483648) : int) }
  
  val function last : int
    ensures { result = (2147483647 : int) }
  
  predicate in_range (x: int) = ((first <= x) /\ (x <= last))
  
  val in_range (x: int) : bool
    ensures { result <-> (in_range (x : int)) }
  
  clone export ada__model.Static_Discrete with
    axiom .,
    type t = integer,
    function first = first,
    function last = last,
    predicate in_range = in_range
  
  type integer__ref = { mutable integer__content : integer }
  
  function integer__ref_integer__content__projection (a: integer__ref) : integer =
    a.integer__content
  
  meta "model_projection" function integer__ref_integer__content__projection
  
  meta "inline:no" function integer__ref_integer__content__projection
  
  val integer__havoc (x: integer__ref) : unit
    writes { x }
end

module Standard__integer___axiom
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__integer as Standard__integer
  
  predicate dynamic_invariant (temp___expr_18: int) (temp___is_init_14: bool) (temp___skip_constant_15: bool) (temp___do_toplevel_16: bool) (temp___do_typ_inv_17: bool) =
    if ((temp___is_init_14 = True) \/
          (Standard__integer.first <= Standard__integer.last)) then
      (((Standard__integer.dynamic_property Standard__integer.first)
          Standard__integer.last)
         temp___expr_18)
    else true
  
  val dynamic_invariant (temp___expr_18: int) (temp___is_init_14: bool) (temp___skip_constant_15: bool) (temp___do_toplevel_16: bool) (temp___do_typ_inv_17: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant (temp___expr_18 : int))
                      (temp___is_init_14 : bool))
                     (temp___skip_constant_15 : bool))
                    (temp___do_toplevel_16 : bool))
                   (temp___do_typ_inv_17 : bool)) }
  
  predicate default_initial_assumption (temp___expr_19: int) (temp___skip_top_level_20: bool) =
    true
  
  val default_initial_assumption (temp___expr_19: int) (temp___skip_top_level_20: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption (temp___expr_19 : int))
                   (temp___skip_top_level_20 : bool)) }
end

module Standard__natural
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  
  type natural = <range 0 2147483647>
  
  val function first : int
    ensures { result = (0 : int) }
  
  val function last : int
    ensures { result = (2147483647 : int) }
  
  predicate in_range (x: int) = ((first <= x) /\ (x <= last))
  
  val in_range (x: int) : bool
    ensures { result <-> (in_range (x : int)) }
  
  clone export ada__model.Static_Discrete with
    axiom .,
    type t = natural,
    function first = first,
    function last = last,
    predicate in_range = in_range
  
  type natural__ref = { mutable natural__content : natural }
  
  function natural__ref_natural__content__projection (a: natural__ref) : natural =
    a.natural__content
  
  meta "model_projection" function natural__ref_natural__content__projection
  
  meta "inline:no" function natural__ref_natural__content__projection
  
  val natural__havoc (x: natural__ref) : unit
    writes { x }
end

module Standard__natural___axiom
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__natural as Standard__natural
  
  predicate dynamic_invariant (temp___expr_46: int) (temp___is_init_42: bool) (temp___skip_constant_43: bool) (temp___do_toplevel_44: bool) (temp___do_typ_inv_45: bool) =
    if ((temp___is_init_42 = True) \/
          (Standard__natural.first <= Standard__natural.last)) then
      (((Standard__natural.dynamic_property Standard__natural.first)
          Standard__natural.last)
         temp___expr_46)
    else true
  
  val dynamic_invariant (temp___expr_46: int) (temp___is_init_42: bool) (temp___skip_constant_43: bool) (temp___do_toplevel_44: bool) (temp___do_typ_inv_45: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant (temp___expr_46 : int))
                      (temp___is_init_42 : bool))
                     (temp___skip_constant_43 : bool))
                    (temp___do_toplevel_44 : bool))
                   (temp___do_typ_inv_45 : bool)) }
  
  predicate default_initial_assumption (temp___expr_47: int) (temp___skip_top_level_48: bool) =
    true
  
  val default_initial_assumption (temp___expr_47: int) (temp___skip_top_level_48: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption (temp___expr_47 : int))
                   (temp___skip_top_level_48 : bool)) }
end

module Standard__natural__rep
  use Standard__natural as Standard__natural
  use _gnatprove_standard.Main
  use int.Int
  
  function to_rep (x: Standard__natural.natural) : int =
    Standard__natural.natural'int x
  
  clone export ada__model.Rep_Proj_Int with
    axiom .,
    type t = Standard__natural.natural,
    predicate in_range = Standard__natural.in_range,
    function to_rep = to_rep
  
  meta "model_projection" function to_rep
  
  meta "inline:no" function to_rep
end

module Standard__positive
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  
  type positive = <range 1 2147483647>
  
  val function first : int
    ensures { result = (1 : int) }
  
  val function last : int
    ensures { result = (2147483647 : int) }
  
  predicate in_range (x: int) = ((first <= x) /\ (x <= last))
  
  val in_range (x: int) : bool
    ensures { result <-> (in_range (x : int)) }
  
  clone export ada__model.Static_Discrete with
    axiom .,
    type t = positive,
    function first = first,
    function last = last,
    predicate in_range = in_range
  
  type positive__ref = { mutable positive__content : positive }
  
  function positive__ref_positive__content__projection (a: positive__ref) : positive =
    a.positive__content
  
  meta "model_projection" function positive__ref_positive__content__projection
  
  meta "inline:no" function positive__ref_positive__content__projection
  
  val positive__havoc (x: positive__ref) : unit
    writes { x }
end

module Standard__positive___axiom
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__positive as Standard__positive
  
  predicate dynamic_invariant (temp___expr_53: int) (temp___is_init_49: bool) (temp___skip_constant_50: bool) (temp___do_toplevel_51: bool) (temp___do_typ_inv_52: bool) =
    if ((temp___is_init_49 = True) \/
          (Standard__positive.first <= Standard__positive.last)) then
      (((Standard__positive.dynamic_property Standard__positive.first)
          Standard__positive.last)
         temp___expr_53)
    else true
  
  val dynamic_invariant (temp___expr_53: int) (temp___is_init_49: bool) (temp___skip_constant_50: bool) (temp___do_toplevel_51: bool) (temp___do_typ_inv_52: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant (temp___expr_53 : int))
                      (temp___is_init_49 : bool))
                     (temp___skip_constant_50 : bool))
                    (temp___do_toplevel_51 : bool))
                   (temp___do_typ_inv_52 : bool)) }
  
  predicate default_initial_assumption (temp___expr_54: int) (temp___skip_top_level_55: bool) =
    true
  
  val default_initial_assumption (temp___expr_54: int) (temp___skip_top_level_55: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption (temp___expr_54 : int))
                   (temp___skip_top_level_55 : bool)) }
end

module Standard__positive__rep
  use Standard__positive as Standard__positive
  use _gnatprove_standard.Main
  use int.Int
  
  function to_rep (x: Standard__positive.positive) : int =
    Standard__positive.positive'int x
  
  clone export ada__model.Rep_Proj_Int with
    axiom .,
    type t = Standard__positive.positive,
    predicate in_range = Standard__positive.in_range,
    function to_rep = to_rep
  
  meta "model_projection" function to_rep
  
  meta "inline:no" function to_rep
end

module Standard__character
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  
  type character
  
  val function first : int
    ensures { result = (0 : int) }
  
  val function last : int
    ensures { result = (255 : int) }
  
  predicate in_range (x: int) = ((first <= x) /\ (x <= last))
  
  val in_range (x: int) : bool
    ensures { result <-> (in_range (x : int)) }
  
  clone export ada__model.Static_Discrete with
    axiom .,
    type t = character,
    function first = first,
    function last = last,
    predicate in_range = in_range
  
  type character__ref = { mutable character__content : character }
  
  function character__ref_character__content__projection (a: character__ref) : character =
    a.character__content
  
  meta "model_projection" function character__ref_character__content__projection
  
  meta "inline:no" function character__ref_character__content__projection
  
  val character__havoc (x: character__ref) : unit
    writes { x }
end

module Standard__character__rep
  use Standard__character as Standard__character
  use _gnatprove_standard.Main
  use int.Int
  clone export ada__model.Rep_Proj_Int with
    axiom .,
    type t = Standard__character.character,
    predicate in_range = Standard__character.in_range
  
  meta "model_projection" function to_rep
  
  meta "inline:no" function to_rep
end

module Array__Int__Standard__character
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__character as Standard__character
  use Standard__character__rep as Standard__character__rep
  
  function index_I1_one : int = 1 : int
  
  type component_type = Standard__character.character
  
  clone export _gnatprove_standard.Array__1 with
    axiom .,
    type I1.t = int,
    predicate I1.le = Int.( <= ),
    predicate I1.lt = Int.( < ),
    predicate I1.gt = Int.( > ),
    function I1.add = Int.( + ),
    function I1.sub = Int.( - ),
    function I1.one = index_I1_one,
    type component_type = component_type
  
  function bool_eq (a: map) (a__first: int) (a__last: int) (b: map) (b__first: int) (b__last: int) : bool =
    ((if (a__first <= a__last) then
        ((b__first <= b__last) /\
           ((a__last - a__first) = (b__last - b__first)))
      else (b__first > b__last)) /\
       (forall temp___idx_98 : int.
          if ((a__first <= temp___idx_98) /\ (temp___idx_98 <= a__last)) then
            ((Standard__character__rep.to_rep ((get a) temp___idx_98))
               = (Standard__character__rep.to_rep
                    ((get b) ((b__first - a__first) + temp___idx_98))))
          else true))
  
  val bool_eq (a: map) (a__first: int) (a__last: int) (b: map) (b__first: int) (b__last: int) : 
    bool
    ensures { result
      =
      ((((((bool_eq (a : map)) (a__first : int)) (a__last : int)) (b : map))
          (b__first : int))
         (b__last : int)) }
  
  axiom bool_eq_rev:
    forall a : map, b : map.
      forall a__first : int, a__last : int, b__first : int, b__last : int.
        ((((((((bool_eq b) b__first) b__last) a) a__first) a__last) = True) ->
           ((if (a__first <= a__last) then
               ((b__first <= b__last) /\
                  ((a__last - a__first) = (b__last - b__first)))
             else (b__first > b__last)) /\
              (forall temp___idx_98 : int.
                 if ((a__first <= temp___idx_98) /\
                       (temp___idx_98 <= a__last)) then
                   ((Standard__character__rep.to_rep ((get a) temp___idx_98))
                      = (Standard__character__rep.to_rep
                           ((get b) ((b__first - a__first) + temp___idx_98))))
                 else true)))
end

module Standard__integer__rep
  use Standard__integer as Standard__integer
  use _gnatprove_standard.Main
  use int.Int
  
  function to_rep (x: Standard__integer.integer) : int =
    Standard__integer.integer'int x
  
  clone export ada__model.Rep_Proj_Int with
    axiom .,
    type t = Standard__integer.integer,
    predicate in_range = Standard__integer.in_range,
    function to_rep = to_rep
  
  meta "model_projection" function to_rep
  
  meta "inline:no" function to_rep
end

module Standard__string
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__integer as Standard__integer
  use Standard__positive as Standard__positive
  use Standard__character as Standard__character
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Standard__integer__rep as Standard__integer__rep
  
  type component_type = Standard__character.character
  
  function index_1_id (x: int) : int = x
  
  clone export ada__model.Unconstr_Array with
    axiom .,
    type map = Array__Int__Standard__character.map,
    function array_bool_eq = Array__Int__Standard__character.bool_eq,
    type index_base_type = Standard__integer.integer,
    type index_rep_type = int,
    function to_rep = Standard__integer__rep.to_rep,
    function rep_to_int = index_1_id,
    predicate in_range_base = Standard__integer.in_range,
    predicate index_dynamic_property = Standard__positive.dynamic_property,
    predicate index_rep_le = Int.( <= )
  
  type string__ = __t
  
  meta "model_projection" function to_array
  
  meta "inline:no" function to_array
  
  meta "model_projection" function first
  
  meta "inline:no" function first
  
  meta "model_projection" function last
  
  meta "inline:no" function last
  
  type string____ref = { mutable string____content : string__ }
  
  function string____ref_string____content__projection (a: string____ref) : string__ =
    a.string____content
  
  meta "model_projection" function string____ref_string____content__projection
  
  meta "inline:no" function string____ref_string____content__projection
  
  val string____havoc (x: string____ref) : unit
    writes { x }
end

module Standard__string___axiom
  use _gnatprove_standard.Main
  use int.Int
  use Standard__positive as Standard__positive
  use Standard__string as Standard__string
  
  predicate dynamic_invariant (temp___expr_103: Standard__string.string__) (temp___is_init_99: bool) (temp___skip_constant_100: bool) (temp___do_toplevel_101: bool) (temp___do_typ_inv_102: bool) =
    if temp___skip_constant_100 then true
    else
      ((((Standard__string.dynamic_property Standard__positive.first)
           Standard__positive.last)
          (Standard__string.first temp___expr_103))
         (Standard__string.last temp___expr_103))
  
  val dynamic_invariant (temp___expr_103: Standard__string.string__) (temp___is_init_99: bool) (temp___skip_constant_100: bool) (temp___do_toplevel_101: bool) (temp___do_typ_inv_102: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant
                       (temp___expr_103 : Standard__string.string__))
                      (temp___is_init_99 : bool))
                     (temp___skip_constant_100 : bool))
                    (temp___do_toplevel_101 : bool))
                   (temp___do_typ_inv_102 : bool)) }
end

module Mystringtokeniser__is_whitespace
  use _gnatprove_standard.Main
  use int.Int
  
  val function is_whitespace (ch: int) : bool
  
  val predicate is_whitespace__function_guard (temp___result_162: bool) (ch: int)
end

module Standard__character___axiom
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__character as Standard__character
  
  predicate dynamic_invariant (temp___expr_81: int) (temp___is_init_77: bool) (temp___skip_constant_78: bool) (temp___do_toplevel_79: bool) (temp___do_typ_inv_80: bool) =
    if ((temp___is_init_77 = True) \/
          (Standard__character.first <= Standard__character.last)) then
      (((Standard__character.dynamic_property Standard__character.first)
          Standard__character.last)
         temp___expr_81)
    else true
  
  val dynamic_invariant (temp___expr_81: int) (temp___is_init_77: bool) (temp___skip_constant_78: bool) (temp___do_toplevel_79: bool) (temp___do_typ_inv_80: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant (temp___expr_81 : int))
                      (temp___is_init_77 : bool))
                     (temp___skip_constant_78 : bool))
                    (temp___do_toplevel_79 : bool))
                   (temp___do_typ_inv_80 : bool)) }
  
  predicate default_initial_assumption (temp___expr_82: int) (temp___skip_top_level_83: bool) =
    true
  
  val default_initial_assumption (temp___expr_82: int) (temp___skip_top_level_83: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption (temp___expr_82 : int))
                   (temp___skip_top_level_83 : bool)) }
end

module Mystringtokeniser__is_whitespace___axiom
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__character___axiom as Standard__character___axiom
  use Mystringtokeniser__is_whitespace as Mystringtokeniser__is_whitespace
  
  val is_whitespace (ch: int) : bool
    requires { true }
    ensures { (((result
                   = (Mystringtokeniser__is_whitespace.is_whitespace ch)) /\
                  ((Mystringtokeniser__is_whitespace.is_whitespace__function_guard
                      result)
                     ch)) /\
                 (result
                    = (((ch = (32 : int)) \/ (ch = (10 : int))) \/
                         (ch = (9 : int))))) }
  
  axiom is_whitespace__post_axiom:
    forall ch : int [Mystringtokeniser__is_whitespace.is_whitespace ch].
      ((((((Standard__character___axiom.dynamic_invariant ch) True) True)
           True)
          True) ->
         (let result = Mystringtokeniser__is_whitespace.is_whitespace ch in
          if ((Mystringtokeniser__is_whitespace.is_whitespace__function_guard
                 result)
                ch) then
            ((true /\ true) /\ true)
          else true))
  
  axiom is_whitespace__def_axiom:
    forall ch : int [Mystringtokeniser__is_whitespace.is_whitespace ch].
      ((Mystringtokeniser__is_whitespace.is_whitespace ch)
         = (((ch = (32 : int)) \/ (ch = (10 : int))) \/ (ch = (9 : int))))
end

module Mystringtokeniser__tokenise__s
  use _gnatprove_standard.Main
  use int.Int
  use Standard__string as Standard__string
  
  val function s : Standard__string.string__
end

module Mystringtokeniser__tokenextent__rep
  use _gnatprove_standard.Main
  use int.Int
  use Standard__natural as Standard__natural
  use Standard__natural__rep as Standard__natural__rep
  use Standard__positive as Standard__positive
  use Standard__positive__rep as Standard__positive__rep
  
  type __split_fields = {
                       rec__mystringtokeniser__tokenextent__start :
                         Standard__positive.positive;
                       rec__mystringtokeniser__tokenextent__length :
                         Standard__natural.natural
                       }
  
  function __split_fields_rec__mystringtokeniser__tokenextent__start__projection (a: __split_fields) : 
    Standard__positive.positive =
    a.rec__mystringtokeniser__tokenextent__start
  
  meta "model_projection" function __split_fields_rec__mystringtokeniser__tokenextent__start__projection
  
  meta "inline:no" function __split_fields_rec__mystringtokeniser__tokenextent__start__projection
  
  function __split_fields_rec__mystringtokeniser__tokenextent__length__projection (a: __split_fields) : 
    Standard__natural.natural =
    a.rec__mystringtokeniser__tokenextent__length
  
  meta "model_projection" function __split_fields_rec__mystringtokeniser__tokenextent__length__projection
  
  meta "inline:no" function __split_fields_rec__mystringtokeniser__tokenextent__length__projection
  
  type __split_fields__ref = {
                            mutable __split_fields__content : __split_fields
                            }
  
  function __split_fields__ref___split_fields__content__projection (a: __split_fields__ref) : __split_fields =
    __split_fields__content a
  
  meta "model_projection" function __split_fields__ref___split_fields__content__projection
  
  meta "inline:no" function __split_fields__ref___split_fields__content__projection
  
  val __split_fields__havoc (x: __split_fields__ref) : unit
    writes { x }
  
  type __rep = { __split_fields : __split_fields }
  
  function __rep___split_fields__projection (a: __rep) : __split_fields =
    __split_fields a
  
  meta "model_projection" function __rep___split_fields__projection
  
  meta "inline:no" function __rep___split_fields__projection
  
  function to_base (a: __rep) : __rep = a
  
  val to_base (a: __rep) : __rep
    ensures { result = (to_base (a : __rep)) }
  
  function of_base (a: __rep) : __rep = a
  
  val of_base (a: __rep) : __rep
    ensures { result = (of_base (a : __rep)) }
  
  predicate mystringtokeniser__tokenextent__start__pred (a: __rep) = true
  
  val mystringtokeniser__tokenextent__start__pred (a: __rep) : bool
    ensures { result
                <->
                (mystringtokeniser__tokenextent__start__pred (a : __rep)) }
  
  val rec__mystringtokeniser__tokenextent__start_ (a: __rep) : Standard__positive.positive
    requires { mystringtokeniser__tokenextent__start__pred a }
    ensures { (result
                 = ((__split_fields a).rec__mystringtokeniser__tokenextent__start)) }
  
  predicate mystringtokeniser__tokenextent__length__pred (a: __rep) = true
  
  val mystringtokeniser__tokenextent__length__pred (a: __rep) : bool
    ensures { result
                <->
                (mystringtokeniser__tokenextent__length__pred (a : __rep)) }
  
  val rec__mystringtokeniser__tokenextent__length_ (a: __rep) : Standard__natural.natural
    requires { mystringtokeniser__tokenextent__length__pred a }
    ensures { (result
                 = ((__split_fields a).rec__mystringtokeniser__tokenextent__length)) }
  
  function bool_eq (a: __rep) (b: __rep) : bool =
    if (((Standard__positive__rep.to_rep
            ((__split_fields a).rec__mystringtokeniser__tokenextent__start))
           = (Standard__positive__rep.to_rep
                ((__split_fields b).rec__mystringtokeniser__tokenextent__start))) /\
          ((Standard__natural__rep.to_rep
              ((__split_fields a).rec__mystringtokeniser__tokenextent__length))
             = (Standard__natural__rep.to_rep
                  ((__split_fields b).rec__mystringtokeniser__tokenextent__length)))) then
      True
    else False
  
  val bool_eq (a: __rep) (b: __rep) : bool
    ensures { result = ((bool_eq (a : __rep)) (b : __rep)) }
end

module Mystringtokeniser__tokenextent
  use export Mystringtokeniser__tokenextent__rep
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  
  type tokenextent = __rep
  
  val function value__size : int
  
  val function object__size : int
  
  val function alignment : int
  
  axiom value__size_axiom: (value__size >= (0 : int))
  
  axiom object__size_axiom: (object__size >= (0 : int))
  
  axiom alignment_axiom: (alignment >= (0 : int))
  
  val function mystringtokeniser__tokenextent__start__first__bit : int
  
  val function mystringtokeniser__tokenextent__start__last__bit : int
  
  val function mystringtokeniser__tokenextent__start__position : int
  
  axiom mystringtokeniser__tokenextent__start__first__bit_axiom:
    (mystringtokeniser__tokenextent__start__first__bit >= (0 : int))
  
  axiom mystringtokeniser__tokenextent__start__last__bit_axiom:
    (mystringtokeniser__tokenextent__start__last__bit
       > mystringtokeniser__tokenextent__start__first__bit)
  
  axiom mystringtokeniser__tokenextent__start__position_axiom:
    (mystringtokeniser__tokenextent__start__position >= (0 : int))
  
  val function mystringtokeniser__tokenextent__length__first__bit : int
  
  val function mystringtokeniser__tokenextent__length__last__bit : int
  
  val function mystringtokeniser__tokenextent__length__position : int
  
  axiom mystringtokeniser__tokenextent__length__first__bit_axiom:
    (mystringtokeniser__tokenextent__length__first__bit >= (0 : int))
  
  axiom mystringtokeniser__tokenextent__length__last__bit_axiom:
    (mystringtokeniser__tokenextent__length__last__bit
       > mystringtokeniser__tokenextent__length__first__bit)
  
  axiom mystringtokeniser__tokenextent__length__position_axiom:
    (mystringtokeniser__tokenextent__length__position >= (0 : int))
  
  val function user_eq (a: tokenextent) (b: tokenextent) : bool
  
  val function dummy : tokenextent
  
  type tokenextent__ref = { mutable tokenextent__content : tokenextent }
  
  function tokenextent__ref_tokenextent__content__projection (a: tokenextent__ref) : tokenextent =
    a.tokenextent__content
  
  meta "model_projection" function tokenextent__ref_tokenextent__content__projection
  
  meta "inline:no" function tokenextent__ref_tokenextent__content__projection
  
  val tokenextent__havoc (x: tokenextent__ref) : unit
    writes { x }
end

module Array__Int__Mystringtokeniser__tokenextent
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Mystringtokeniser__tokenextent as Mystringtokeniser__tokenextent
  
  function index_I1_one : int = 1 : int
  
  type component_type = Mystringtokeniser__tokenextent.tokenextent
  
  clone export _gnatprove_standard.Array__1 with
    axiom .,
    type I1.t = int,
    predicate I1.le = Int.( <= ),
    predicate I1.lt = Int.( < ),
    predicate I1.gt = Int.( > ),
    function I1.add = Int.( + ),
    function I1.sub = Int.( - ),
    function I1.one = index_I1_one,
    type component_type = component_type
  
  function bool_eq (a: map) (a__first: int) (a__last: int) (b: map) (b__first: int) (b__last: int) : bool =
    ((if (a__first <= a__last) then
        ((b__first <= b__last) /\
           ((a__last - a__first) = (b__last - b__first)))
      else (b__first > b__last)) /\
       (forall temp___idx_161 : int.
          if ((a__first <= temp___idx_161) /\ (temp___idx_161 <= a__last)) then
            ((Mystringtokeniser__tokenextent.bool_eq ((get a) temp___idx_161))
               ((get b) ((b__first - a__first) + temp___idx_161)))
          else true))
  
  val bool_eq (a: map) (a__first: int) (a__last: int) (b: map) (b__first: int) (b__last: int) : 
    bool
    ensures { result
      =
      ((((((bool_eq (a : map)) (a__first : int)) (a__last : int)) (b : map))
          (b__first : int))
         (b__last : int)) }
  
  axiom bool_eq_rev:
    forall a : map, b : map.
      forall a__first : int, a__last : int, b__first : int, b__last : int.
        ((((((((bool_eq b) b__first) b__last) a) a__first) a__last) = True) ->
           ((if (a__first <= a__last) then
               ((b__first <= b__last) /\
                  ((a__last - a__first) = (b__last - b__first)))
             else (b__first > b__last)) /\
              (forall temp___idx_161 : int.
                 if ((a__first <= temp___idx_161) /\
                       (temp___idx_161 <= a__last)) then
                   ((Mystringtokeniser__tokenextent.bool_eq
                       ((get a) temp___idx_161))
                      ((get b) ((b__first - a__first) + temp___idx_161)))
                 else true)))
end

module Mystringtokeniser__tokenise__tokens
  use _gnatprove_standard.Main
  use int.Int
  use Standard__integer as Standard__integer
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  
  val tokens : Array__Int__Mystringtokeniser__tokenextent.map__ref
  
  val function tokens__first : Standard__integer.integer
  
  val function tokens__last : Standard__integer.integer
end

module Mystringtokeniser__tokenise__count
  use _gnatprove_standard.Main
  use int.Int
  
  val count : int__ref
end

module Mystringtokeniser__tokenise__index
  use _gnatprove_standard.Main
  use int.Int
  
  val index : int__ref
end

module Mystringtokeniser__tokenise__extent
  use _gnatprove_standard.Main
  use int.Int
  use Mystringtokeniser__tokenextent as Mystringtokeniser__tokenextent
  
  val extent__split_fields : Mystringtokeniser__tokenextent.__split_fields__ref
end

module Mystringtokeniser__tokenextent___axiom
  use _gnatprove_standard.Main
  use int.Int
  use Mystringtokeniser__tokenextent as Mystringtokeniser__tokenextent
  
  predicate dynamic_invariant (temp___expr_167: Mystringtokeniser__tokenextent.tokenextent) (temp___is_init_163: bool) (temp___skip_constant_164: bool) (temp___do_toplevel_165: bool) (temp___do_typ_inv_166: bool) =
    true
  
  val dynamic_invariant (temp___expr_167: Mystringtokeniser__tokenextent.tokenextent) (temp___is_init_163: bool) (temp___skip_constant_164: bool) (temp___do_toplevel_165: bool) (temp___do_typ_inv_166: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant
                       (temp___expr_167 :
                          Mystringtokeniser__tokenextent.tokenextent))
                      (temp___is_init_163 : bool))
                     (temp___skip_constant_164 : bool))
                    (temp___do_toplevel_165 : bool))
                   (temp___do_typ_inv_166 : bool)) }
  
  predicate default_initial_assumption (temp___expr_168: Mystringtokeniser__tokenextent.tokenextent) (temp___skip_top_level_169: bool) =
    true
  
  val default_initial_assumption (temp___expr_168: Mystringtokeniser__tokenextent.tokenextent) (temp___skip_top_level_169: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption
                    (temp___expr_168 :
                       Mystringtokeniser__tokenextent.tokenextent))
                   (temp___skip_top_level_169 : bool)) }
end

module Mystringtokeniser__tokenise__outindex
  use _gnatprove_standard.Main
  use int.Int
  
  val outindex : int__ref
end

module Mystringtokeniser__tokenarray
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use Standard__integer as Standard__integer
  use Standard__positive as Standard__positive
  use Standard__integer__rep as Standard__integer__rep
  use Mystringtokeniser__tokenextent as Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  
  type component_type = Mystringtokeniser__tokenextent.tokenextent
  
  function index_1_id (x: int) : int = x
  
  clone export ada__model.Unconstr_Array with
    axiom .,
    type map = Array__Int__Mystringtokeniser__tokenextent.map,
    function array_bool_eq = Array__Int__Mystringtokeniser__tokenextent.bool_eq,
    type index_base_type = Standard__integer.integer,
    type index_rep_type = int,
    function to_rep = Standard__integer__rep.to_rep,
    function rep_to_int = index_1_id,
    predicate in_range_base = Standard__integer.in_range,
    predicate index_dynamic_property = Standard__positive.dynamic_property,
    predicate index_rep_le = Int.( <= )
  
  type tokenarray = __t
  
  meta "model_projection" function to_array
  
  meta "inline:no" function to_array
  
  meta "model_projection" function first
  
  meta "inline:no" function first
  
  meta "model_projection" function last
  
  meta "inline:no" function last
  
  type tokenarray__ref = { mutable tokenarray__content : tokenarray }
  
  function tokenarray__ref_tokenarray__content__projection (a: tokenarray__ref) : tokenarray =
    a.tokenarray__content
  
  meta "model_projection" function tokenarray__ref_tokenarray__content__projection
  
  meta "inline:no" function tokenarray__ref_tokenarray__content__projection
  
  val tokenarray__havoc (x: tokenarray__ref) : unit
    writes { x }
end

module Mystringtokeniser__tokenise__S2b
  use export Mystringtokeniser__tokenarray
  use _gnatprove_standard.Main
  use int.Int
  
  type s2b = tokenarray
  
  type s2b__ref = { mutable s2b__content : s2b }
  
  function s2b__ref_s2b__content__projection (a: s2b__ref) : s2b =
    a.s2b__content
  
  meta "model_projection" function s2b__ref_s2b__content__projection
  
  meta "inline:no" function s2b__ref_s2b__content__projection
  
  val s2b__havoc (x: s2b__ref) : unit
    writes { x }
end

module Mystringtokeniser__tokenise__L_1
  use _gnatprove_standard.Main
  use int.Int
  
  exception L_1
end

module Mystringtokeniser__tokenise__L_2
  use _gnatprove_standard.Main
  use int.Int
  
  exception L_2
end

module Mystringtokeniser__tokenise__L_3
  use _gnatprove_standard.Main
  use int.Int
  
  exception L_3
end

module Mystringtokeniser__tokenise__index___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__extent___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__outindex___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__L_2___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__L_3___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__L_1___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenarray___axiom
  use _gnatprove_standard.Main
  use int.Int
  use Standard__positive as Standard__positive
  use Mystringtokeniser__tokenarray as Mystringtokeniser__tokenarray
  
  predicate dynamic_invariant (temp___expr_176: Mystringtokeniser__tokenarray.tokenarray) (temp___is_init_172: bool) (temp___skip_constant_173: bool) (temp___do_toplevel_174: bool) (temp___do_typ_inv_175: bool) =
    if temp___skip_constant_173 then true
    else
      ((((Mystringtokeniser__tokenarray.dynamic_property
            Standard__positive.first)
           Standard__positive.last)
          (Mystringtokeniser__tokenarray.first temp___expr_176))
         (Mystringtokeniser__tokenarray.last temp___expr_176))
  
  val dynamic_invariant (temp___expr_176: Mystringtokeniser__tokenarray.tokenarray) (temp___is_init_172: bool) (temp___skip_constant_173: bool) (temp___do_toplevel_174: bool) (temp___do_typ_inv_175: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant
                       (temp___expr_176 :
                          Mystringtokeniser__tokenarray.tokenarray))
                      (temp___is_init_172 : bool))
                     (temp___skip_constant_173 : bool))
                    (temp___do_toplevel_174 : bool))
                   (temp___do_typ_inv_175 : bool)) }
end

module Mystringtokeniser__tokenise__s___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__tokens___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__count___axiom
  use _gnatprove_standard.Main
  use int.Int
end

module Mystringtokeniser__tokenise__S2b___axiom
  use _gnatprove_standard.Main
  use int.Int
  use Standard__integer__rep as Standard__integer__rep
  use Mystringtokeniser__tokenise__tokens as Mystringtokeniser__tokenise__tokens
  use Mystringtokeniser__tokenise__S2b as Mystringtokeniser__tokenise__S2b
  
  predicate dynamic_invariant (temp___expr_189: Mystringtokeniser__tokenise__S2b.s2b) (temp___is_init_185: bool) (temp___skip_constant_186: bool) (temp___do_toplevel_187: bool) (temp___do_typ_inv_188: bool) =
    if temp___skip_constant_186 then true
    else
      ((((((Mystringtokeniser__tokenise__S2b.dynamic_property
              (Standard__integer__rep.to_rep
                 Mystringtokeniser__tokenise__tokens.tokens__first))
             (Standard__integer__rep.to_rep
                Mystringtokeniser__tokenise__tokens.tokens__last))
            (Mystringtokeniser__tokenise__S2b.first temp___expr_189))
           (Mystringtokeniser__tokenise__S2b.last temp___expr_189)) /\
          ((Mystringtokeniser__tokenise__S2b.first temp___expr_189)
             = (Standard__integer__rep.to_rep
                  Mystringtokeniser__tokenise__tokens.tokens__first))) /\
         ((Mystringtokeniser__tokenise__S2b.last temp___expr_189)
            = (Standard__integer__rep.to_rep
                 Mystringtokeniser__tokenise__tokens.tokens__last)))
  
  val dynamic_invariant (temp___expr_189: Mystringtokeniser__tokenise__S2b.s2b) (temp___is_init_185: bool) (temp___skip_constant_186: bool) (temp___do_toplevel_187: bool) (temp___do_typ_inv_188: bool) : 
    bool
    ensures { result
                <->
                (((((dynamic_invariant
                       (temp___expr_189 :
                          Mystringtokeniser__tokenise__S2b.s2b))
                      (temp___is_init_185 : bool))
                     (temp___skip_constant_186 : bool))
                    (temp___do_toplevel_187 : bool))
                   (temp___do_typ_inv_188 : bool)) }
  
  predicate default_initial_assumption (temp___expr_191: Mystringtokeniser__tokenise__S2b.s2b) (temp___skip_top_level_192: bool) =
    ((true /\
        ((Mystringtokeniser__tokenise__S2b.first temp___expr_191)
           = (Standard__integer__rep.to_rep
                Mystringtokeniser__tokenise__tokens.tokens__first))) /\
       ((Mystringtokeniser__tokenise__S2b.last temp___expr_191)
          = (Standard__integer__rep.to_rep
               Mystringtokeniser__tokenise__tokens.tokens__last)))
  
  val default_initial_assumption (temp___expr_191: Mystringtokeniser__tokenise__S2b.s2b) (temp___skip_top_level_192: bool) : 
    bool
    ensures { result
                <->
                ((default_initial_assumption
                    (temp___expr_191 : Mystringtokeniser__tokenise__S2b.s2b))
                   (temp___skip_top_level_192 : bool)) }
end

module Mystringtokeniser__tokenise__subprogram_def
  use _gnatprove_standard.Main
  use int.Int
  use int.Int
  use _gnatprove_standard.Main as Main
  use _gnatprove_standard.Integer as Integer
  use _gnatprove_standard.Boolean as Boolean
  use Standard__integer as Standard__integer
  use Standard__integer___axiom as Standard__integer___axiom
  use Standard__natural as Standard__natural
  use Standard__natural___axiom as Standard__natural___axiom
  use Standard__natural__rep as Standard__natural__rep
  use Standard__positive as Standard__positive
  use Standard__positive___axiom as Standard__positive___axiom
  use Standard__positive__rep as Standard__positive__rep
  use Standard__character as Standard__character
  use Standard__character__rep as Standard__character__rep
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Standard__string as Standard__string
  use Standard__integer__rep as Standard__integer__rep
  use Standard__string___axiom as Standard__string___axiom
  use Mystringtokeniser__is_whitespace as Mystringtokeniser__is_whitespace
  use Mystringtokeniser__is_whitespace___axiom as Mystringtokeniser__is_whitespace___axiom
  use Mystringtokeniser__tokenise__s as Mystringtokeniser__tokenise__s
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Mystringtokeniser__tokenise__tokens as Mystringtokeniser__tokenise__tokens
  use Mystringtokeniser__tokenise__count as Mystringtokeniser__tokenise__count
  use Mystringtokeniser__tokenise__index as Mystringtokeniser__tokenise__index
  use Mystringtokeniser__tokenise__extent as Mystringtokeniser__tokenise__extent
  use Mystringtokeniser__tokenextent as Mystringtokeniser__tokenextent
  use Mystringtokeniser__tokenextent___axiom as Mystringtokeniser__tokenextent___axiom
  use Mystringtokeniser__tokenise__outindex as Mystringtokeniser__tokenise__outindex
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Mystringtokeniser__tokenarray as Mystringtokeniser__tokenarray
  use Mystringtokeniser__tokenise__S2b as Mystringtokeniser__tokenise__S2b
  use Mystringtokeniser__tokenise__L_1 as Mystringtokeniser__tokenise__L_1
  use Mystringtokeniser__tokenise__L_2 as Mystringtokeniser__tokenise__L_2
  use Mystringtokeniser__tokenise__L_3 as Mystringtokeniser__tokenise__L_3
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Standard__character as Array__Int__Standard__character
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Array__Int__Mystringtokeniser__tokenextent as Array__Int__Mystringtokeniser__tokenextent
  use Standard__integer___axiom as Standard__integer___axiom
  use Standard__natural___axiom as Standard__natural___axiom
  use Standard__positive___axiom as Standard__positive___axiom
  use Standard__character___axiom as Standard__character___axiom
  use Standard__string___axiom as Standard__string___axiom
  use Standard__integer___axiom as Standard__integer___axiom
  use Mystringtokeniser__tokenise__index___axiom as Mystringtokeniser__tokenise__index___axiom
  use Mystringtokeniser__tokenise__extent___axiom as Mystringtokeniser__tokenise__extent___axiom
  use Mystringtokeniser__tokenise__outindex___axiom as Mystringtokeniser__tokenise__outindex___axiom
  use Mystringtokeniser__tokenise__L_2___axiom as Mystringtokeniser__tokenise__L_2___axiom
  use Mystringtokeniser__tokenise__L_3___axiom as Mystringtokeniser__tokenise__L_3___axiom
  use Mystringtokeniser__tokenise__L_1___axiom as Mystringtokeniser__tokenise__L_1___axiom
  use Mystringtokeniser__tokenextent___axiom as Mystringtokeniser__tokenextent___axiom
  use Mystringtokeniser__tokenarray___axiom as Mystringtokeniser__tokenarray___axiom
  use Mystringtokeniser__is_whitespace___axiom as Mystringtokeniser__is_whitespace___axiom
  use Mystringtokeniser__tokenise__s___axiom as Mystringtokeniser__tokenise__s___axiom
  use Mystringtokeniser__tokenise__tokens___axiom as Mystringtokeniser__tokenise__tokens___axiom
  use Mystringtokeniser__tokenise__count___axiom as Mystringtokeniser__tokenise__count___axiom
  use Mystringtokeniser__tokenise__S2b___axiom as Mystringtokeniser__tokenise__S2b___axiom
  
  let def (__void_param : unit)
    requires { [#"mystringtokeniser.ads" 16 0 0] true }
    ensures { [#"mystringtokeniser.ads" 16 0 0]
              [#"mystringtokeniser.ads" 18 0 0]
              [@GP_Reason:VC_POSTCONDITION]
              [@GP_Sloc:mystringtokeniser.ads:18:14]
              [@GP_Id:32]
              [@model_vc_post]
              [@comment:     Post => Count <= Tokens'Length and              ^ mystringtokeniser.ads:18:14:VC_POSTCONDITION]
              [@GP_Shape:pragargs__and]
              (([@GP_Pretty_Ada:1209]
                [@GP_Sloc:mystringtokeniser.ads:18:14]
                ((Mystringtokeniser__tokenise__count.count.int__content)
                   <= ((Integer.length
                          (Standard__integer__rep.to_rep
                             Mystringtokeniser__tokenise__tokens.tokens__first))
                         (Standard__integer__rep.to_rep
                            Mystringtokeniser__tokenise__tokens.tokens__last)))) /\
                 (forall index : int.
                    ((((Standard__integer__rep.to_rep
                          Mystringtokeniser__tokenise__tokens.tokens__first)
                         <= index) /\
                        (index
                           <= ((Standard__integer__rep.to_rep
                                  Mystringtokeniser__tokenise__tokens.tokens__first)
                                 + ((Mystringtokeniser__tokenise__count.count.int__content)
                                      - (1 : int))))) ->
                       ((([@GP_Pretty_Ada:1233]
                          [@GP_Sloc:mystringtokeniser.ads:20:12]
                          ((Standard__positive__rep.to_rep
                              ((Mystringtokeniser__tokenextent.__split_fields
                                   (let temp___261 =
                                      ((Mystringtokeniser__tokenise__S2b.of_array
                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                         (Standard__integer__rep.to_rep
                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                        (Standard__integer__rep.to_rep
                                           Mystringtokeniser__tokenise__tokens.tokens__last) in
                                    (Array__Int__Mystringtokeniser__tokenextent.get
                                       (Mystringtokeniser__tokenise__S2b.to_array
                                          temp___261))
                                      index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                             >= (Standard__string.first
                                   Mystringtokeniser__tokenise__s.s))) /\
                           ([@GP_Sloc:mystringtokeniser.ads:21:11]
                            [@GP_Pretty_Ada:1243]
                            ((Standard__natural__rep.to_rep
                                ((Mystringtokeniser__tokenextent.__split_fields
                                     (let temp___262 =
                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                      (Array__Int__Mystringtokeniser__tokenextent.get
                                         (Mystringtokeniser__tokenise__S2b.to_array
                                            temp___262))
                                        index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                               > (0 : int)))) /\
                          ([@GP_Sloc:mystringtokeniser.ads:22:13]
                           [@GP_Pretty_Ada:1253]
                           (((Standard__natural__rep.to_rep
                                ((Mystringtokeniser__tokenextent.__split_fields
                                     (let temp___263 =
                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                      (Array__Int__Mystringtokeniser__tokenextent.get
                                         (Mystringtokeniser__tokenise__S2b.to_array
                                            temp___263))
                                        index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                               - (1 : int))
                              <= ((Standard__string.last
                                     Mystringtokeniser__tokenise__s.s)
                                    - (Standard__positive__rep.to_rep
                                         ((Mystringtokeniser__tokenextent.__split_fields
                                              (let temp___264 =
                                                 ((Mystringtokeniser__tokenise__S2b.of_array
                                                     (Mystringtokeniser__tokenise__tokens.tokens.
                                                        Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                    (Standard__integer__rep.to_rep
                                                       Mystringtokeniser__tokenise__tokens.tokens__first))
                                                   (Standard__integer__rep.to_rep
                                                      Mystringtokeniser__tokenise__tokens.tokens__last) in
                                               (Array__Int__Mystringtokeniser__tokenextent.get
                                                  (Mystringtokeniser__tokenise__S2b.to_array
                                                     temp___264))
                                                 index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))))))))) }
  = [@vc:divergent]
    (([@GNAT-comment:Assume dynamic invariants of inputs of the subprogram mystringtokeniser.ads:16]
      ());
     assume {
       ((((Standard__string___axiom.dynamic_invariant
             Mystringtokeniser__tokenise__s.s)
            True)
           False)
          True)
         True };
     assume {
       ((if False then true
         else
           ((((Mystringtokeniser__tokenarray.dynamic_property
                 Standard__positive.first)
                Standard__positive.last)
               (Mystringtokeniser__tokenise__S2b.first
                  (((Mystringtokeniser__tokenise__S2b.of_array
                       (Mystringtokeniser__tokenise__tokens.tokens.Array__Int__Mystringtokeniser__tokenextent.map__content))
                      (Standard__integer__rep.to_rep
                         Mystringtokeniser__tokenise__tokens.tokens__first))
                     (Standard__integer__rep.to_rep
                        Mystringtokeniser__tokenise__tokens.tokens__last))))
              (Mystringtokeniser__tokenise__S2b.last
                 (((Mystringtokeniser__tokenise__S2b.of_array
                      (Mystringtokeniser__tokenise__tokens.tokens.Array__Int__Mystringtokeniser__tokenextent.map__content))
                     (Standard__integer__rep.to_rep
                        Mystringtokeniser__tokenise__tokens.tokens__first))
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__last))))) /\
          (forall temp___258 : int.
             if (((Mystringtokeniser__tokenise__S2b.first
                     (((Mystringtokeniser__tokenise__S2b.of_array
                          (Mystringtokeniser__tokenise__tokens.tokens.
                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                         (Standard__integer__rep.to_rep
                            Mystringtokeniser__tokenise__tokens.tokens__first))
                        (Standard__integer__rep.to_rep
                           Mystringtokeniser__tokenise__tokens.tokens__last)))
                    <= temp___258) /\
                   (temp___258
                      <= (Mystringtokeniser__tokenise__S2b.last
                            (((Mystringtokeniser__tokenise__S2b.of_array
                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                (Standard__integer__rep.to_rep
                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                               (Standard__integer__rep.to_rep
                                  Mystringtokeniser__tokenise__tokens.tokens__last))))) then
               (((((Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                      ((Array__Int__Mystringtokeniser__tokenextent.get
                          (Mystringtokeniser__tokenise__S2b.to_array
                             (((Mystringtokeniser__tokenise__S2b.of_array
                                  (Mystringtokeniser__tokenise__tokens.tokens.
                                     Array__Int__Mystringtokeniser__tokenextent.map__content))
                                 (Standard__integer__rep.to_rep
                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                (Standard__integer__rep.to_rep
                                   Mystringtokeniser__tokenise__tokens.tokens__last))))
                         temp___258))
                     True)
                    False)
                   True)
                  True)
             else true)) };
     assume {
       ((((Standard__natural___axiom.dynamic_invariant
             (Mystringtokeniser__tokenise__count.count.int__content))
            False)
           False)
          True)
         True };
     ([@GNAT-comment:Assume moved pointers in outputs of the subprogram mystringtokeniser.ads:16]
      ());
     ([@GNAT-comment:Check for RTE in the Pre of the subprogram mystringtokeniser.ads:16]
      ());
     (begin
        ensures { true }
        let _ =
          let _ =
            (Boolean.andb
               (if ((Standard__string.length Mystringtokeniser__tokenise__s.s)
                      > (0 : int)) then
                  ((Standard__string.first Mystringtokeniser__tokenise__s.s)
                     <= (Standard__string.last
                           Mystringtokeniser__tokenise__s.s))
                else (Boolean.of_int (1 : int))))
              ((Standard__integer__rep.to_rep
                  ((begin
                      ensures { true }
                      let _ =
                        let _ =
                          ((Mystringtokeniser__tokenise__S2b.of_array
                              (Mystringtokeniser__tokenise__tokens.tokens.
                                 Array__Int__Mystringtokeniser__tokenextent.map__content))
                             (Standard__integer__rep.to_rep
                                Mystringtokeniser__tokenise__tokens.tokens__first))
                            (Standard__integer__rep.to_rep
                               Mystringtokeniser__tokenise__tokens.tokens__last) in
                        () in
                      ()
                    end);
                   Mystringtokeniser__tokenise__tokens.tokens__first))
                 <= (Standard__integer__rep.to_rep
                       ((begin
                           ensures { true }
                           let _ =
                             let _ =
                               ((Mystringtokeniser__tokenise__S2b.of_array
                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                      Array__Int__Mystringtokeniser__tokenextent.map__content))
                                  (Standard__integer__rep.to_rep
                                     Mystringtokeniser__tokenise__tokens.tokens__first))
                                 (Standard__integer__rep.to_rep
                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                             () in
                           ()
                         end);
                        Mystringtokeniser__tokenise__tokens.tokens__last))) in
          () in
        ()
      end);
     ([@GNAT-comment:Assume Pre of the subprogram mystringtokeniser.ads:16]
      ());
     assume {
       ((if ((Standard__string.length Mystringtokeniser__tokenise__s.s)
               > (0 : int)) then
           ([@GP_Pretty_Ada:1192]
            ((Standard__string.first Mystringtokeniser__tokenise__s.s)
               <= (Standard__string.last Mystringtokeniser__tokenise__s.s)))
         else ([@GP_Pretty_Ada:3150] true)) /\
          ([@GP_Pretty_Ada:1201]
           ((Standard__integer__rep.to_rep
               Mystringtokeniser__tokenise__tokens.tokens__first)
              <= (Standard__integer__rep.to_rep
                    Mystringtokeniser__tokenise__tokens.tokens__last)))) };
     (try
        ([#"mystringtokeniser.adb" 6 0 0] ());
        ([#"mystringtokeniser.adb" 6 0 0] ());
        ([#"mystringtokeniser.adb" 7 0 0]
         (([#"mystringtokeniser.adb" 7 0 0]
           assume {
             [#"mystringtokeniser.adb" 7 0 0]
             ((Standard__positive___axiom.default_initial_assumption
                 (Mystringtokeniser__tokenise__index.index.int__content))
                False) });
          ([#"mystringtokeniser.adb" 7 0 0]
           assume {
             [#"mystringtokeniser.adb" 7 0 0]
             (((((Standard__positive___axiom.dynamic_invariant
                    (Mystringtokeniser__tokenise__index.index.int__content))
                   False)
                  False)
                 True)
                True) })));
        ([#"mystringtokeniser.adb" 8 0 0]
         (([#"mystringtokeniser.adb" 8 0 0] ());
          ([#"mystringtokeniser.adb" 8 0 0]
           assume {
             [#"mystringtokeniser.adb" 8 0 0]
             ((Mystringtokeniser__tokenextent___axiom.default_initial_assumption
                 { Mystringtokeniser__tokenextent.__split_fields =
                     (Mystringtokeniser__tokenextent.__split_fields__content
                         Mystringtokeniser__tokenise__extent.extent__split_fields) })
                False) });
          ([#"mystringtokeniser.adb" 8 0 0]
           assume {
             [#"mystringtokeniser.adb" 8 0 0]
             (((((Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                    { Mystringtokeniser__tokenextent.__split_fields =
                        (Mystringtokeniser__tokenextent.__split_fields__content
                            Mystringtokeniser__tokenise__extent.extent__split_fields) })
                   False)
                  False)
                 True)
                True) })));
        ([#"mystringtokeniser.adb" 9 0 0]
         (([#"mystringtokeniser.adb" 9 0 0]
           (Mystringtokeniser__tokenise__outindex.outindex.int__content <-
              (Standard__integer__rep.to_rep
                 (([#"mystringtokeniser.adb" 9 0 0]
                   (begin
                      ensures { true }
                      let _ =
                        let _ =
                          ((Mystringtokeniser__tokenise__S2b.of_array
                              (Mystringtokeniser__tokenise__tokens.tokens.
                                 Array__Int__Mystringtokeniser__tokenextent.map__content))
                             (Standard__integer__rep.to_rep
                                Mystringtokeniser__tokenise__tokens.tokens__first))
                            (Standard__integer__rep.to_rep
                               Mystringtokeniser__tokenise__tokens.tokens__last) in
                        () in
                      ()
                    end));
                  Mystringtokeniser__tokenise__tokens.tokens__first))));
          ([#"mystringtokeniser.adb" 9 0 0]
           assume {
             [#"mystringtokeniser.adb" 9 0 0]
             (((((Standard__integer___axiom.dynamic_invariant
                    (Mystringtokeniser__tokenise__outindex.outindex.int__content))
                   True)
                  False)
                 True)
                True) })));
        ([#"mystringtokeniser.adb" 26 0 0] ());
        ([#"mystringtokeniser.adb" 35 0 0] ());
        ([#"mystringtokeniser.adb" 16 0 0] ());
        ([@GP_Sloc:mystringtokeniser.adb:11:13]
         [#"mystringtokeniser.adb" 11 0 0]
         [#"mystringtokeniser.adb" 11 0 0]
         (Mystringtokeniser__tokenise__count.count.int__content <- (0 : int)));
        ([@GP_Sloc:mystringtokeniser.adb:12:7]
         [#"mystringtokeniser.adb" 12 0 0]
         (if (([#"mystringtokeniser.adb" 12 0 0]
               [#"mystringtokeniser.adb" 12 0 0]
               (([@branch_id=849] Main.spark__branch).bool__content <-
                  ((([#"mystringtokeniser.adb" 12 0 0] ());
                    (Standard__string.first Mystringtokeniser__tokenise__s.s))
                     > (([#"mystringtokeniser.adb" 12 0 0] ());
                        (Standard__string.last
                           Mystringtokeniser__tokenise__s.s)))));
              (([@branch_id=849] Main.spark__branch).bool__content)) then
            ([@GP_Sloc:mystringtokeniser.adb:13:10]
             [#"mystringtokeniser.adb" 13 0 0]
             [#"mystringtokeniser.adb" 13 0 0] ((raise Return__exc) : unit))
          else ()));
        ([@GP_Sloc:mystringtokeniser.adb:15:7]
         [#"mystringtokeniser.adb" 15 0 0] ());
        ([@GP_Sloc:mystringtokeniser.adb:15:13]
         [#"mystringtokeniser.adb" 15 0 0]
         [#"mystringtokeniser.adb" 15 0 0]
         (Mystringtokeniser__tokenise__index.index.int__content <-
            ([#"mystringtokeniser.adb" 15 0 0]
             [@vc:annotation]
             [@GP_Shape:index_assign__first_ref]
             [@GP_Reason:VC_RANGE_CHECK]
             [@GP_Sloc:mystringtokeniser.adb:15:17]
             [@GP_Id:0]
             [@comment:      Index := S'First;                 ^ mystringtokeniser.adb:15:17:VC_RANGE_CHECK]
             (Standard__positive.range_check_
                (([#"mystringtokeniser.adb" 15 0 0] ());
                 (Standard__string.first Mystringtokeniser__tokenise__s.s))))));
        ([@GP_Sloc:mystringtokeniser.adb:16:83]
         [#"mystringtokeniser.adb" 16 0 0]
         (([@GNAT-comment:Translation of an Ada loop from mystringtokeniser.adb:16]
           ());
          (if ((Boolean.andb
                  ((Boolean.andb
                      ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                         <= (Standard__integer__rep.to_rep
                               (([#"mystringtokeniser.adb" 16 0 0]
                                 (begin
                                    ensures { true }
                                    let _ =
                                      let _ =
                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                      () in
                                    ()
                                  end));
                                Mystringtokeniser__tokenise__tokens.tokens__last))))
                     ((Mystringtokeniser__tokenise__index.index.int__content)
                        <= (([#"mystringtokeniser.adb" 16 0 0] ());
                            (Standard__string.last
                               Mystringtokeniser__tokenise__s.s)))))
                 ((Mystringtokeniser__tokenise__count.count.int__content)
                    < ([#"mystringtokeniser.adb" 16 0 0]
                       [@GP_Shape:L_1_while__and__cmp__typeconv__length_ref]
                       [@comment:      while OutIndex <= Tokens'Last and Index <= S'Last and Count < Tokens'Length loop                                                                           ^ mystringtokeniser.adb:16:75:VC_RANGE_CHECK]
                       [@GP_Sloc:mystringtokeniser.adb:16:75]
                       [@vc:annotation]
                       [@GP_Reason:VC_RANGE_CHECK]
                       [@GP_Id:24]
                       (Standard__integer.range_check_
                          (([#"mystringtokeniser.adb" 16 0 0]
                            (begin
                               ensures { true }
                               let _ =
                                 let _ =
                                   ((Mystringtokeniser__tokenise__S2b.of_array
                                       (Mystringtokeniser__tokenise__tokens.tokens.
                                          Array__Int__Mystringtokeniser__tokenextent.map__content))
                                      (Standard__integer__rep.to_rep
                                         Mystringtokeniser__tokenise__tokens.tokens__first))
                                     (Standard__integer__rep.to_rep
                                        Mystringtokeniser__tokenise__tokens.tokens__last) in
                                 () in
                               ()
                             end));
                           ((Integer.length
                               (Standard__integer__rep.to_rep
                                  Mystringtokeniser__tokenise__tokens.tokens__first))
                              (Standard__integer__rep.to_rep
                                 Mystringtokeniser__tokenise__tokens.tokens__last))))))) then
             (try
                let temp___loop_entry_234 =
                  { Mystringtokeniser__tokenextent.__split_fields =
                      (Mystringtokeniser__tokenextent.__split_fields__content
                          Mystringtokeniser__tokenise__extent.extent__split_fields) } in
                let temp___loop_entry_232 =
                  ((Mystringtokeniser__tokenise__S2b.of_array
                      (Mystringtokeniser__tokenise__tokens.tokens.Array__Int__Mystringtokeniser__tokenextent.map__content))
                     (Standard__integer__rep.to_rep
                        Mystringtokeniser__tokenise__tokens.tokens__first))
                    (Standard__integer__rep.to_rep
                       Mystringtokeniser__tokenise__tokens.tokens__last) in
                ([@GNAT-comment:While loop translating the Ada loop from mystringtokeniser.adb:16]
                 ());
                ([#"'@Loop 931@'mystringtokeniser.adb" 23 0 0]
                 [#"'@Loop 931@'mystringtokeniser.adb" 23 0 0]
                 ((([@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                    ());
                   (let temp___inv_236 =
                      (let j = val _f : int in
                               _f in
                       if ((Boolean.andb
                              ((Standard__integer__rep.to_rep
                                  ((begin
                                      ensures { true }
                                      let _ =
                                        let _ =
                                          ((Mystringtokeniser__tokenise__S2b.of_array
                                              (Mystringtokeniser__tokenise__tokens.tokens.
                                                 Array__Int__Mystringtokeniser__tokenextent.map__content))
                                             (Standard__integer__rep.to_rep
                                                Mystringtokeniser__tokenise__tokens.tokens__first))
                                            (Standard__integer__rep.to_rep
                                               Mystringtokeniser__tokenise__tokens.tokens__last) in
                                        () in
                                      ()
                                    end);
                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                 <= j))
                             (j
                                <= ([#"mystringtokeniser.adb" 18 0 0]
                                    [@GP_Id:17]
                                    [@comment:           (for all J in Tokens'First..OutIndex-1 =>                                                ^ mystringtokeniser.adb:18:48:VC_OVERFLOW_CHECK]
                                    [@vc:annotation]
                                    [@GP_Reason:VC_OVERFLOW_CHECK]
                                    [@GP_Shape:L_1_while__pragargs__forall__range__sub]
                                    [@GP_Sloc:mystringtokeniser.adb:18:48]
                                    (Standard__integer.range_check_
                                       ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                          - (1 : int)))))) then
                         (begin
                            ensures { true }
                            let _ =
                              let _ =
                                ((Boolean.andb
                                    ((Standard__positive__rep.to_rep
                                        ((Mystringtokeniser__tokenextent.__split_fields
                                             (let temp___237 =
                                                ((Mystringtokeniser__tokenise__S2b.of_array
                                                    (Mystringtokeniser__tokenise__tokens.tokens.
                                                       Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                   (Standard__integer__rep.to_rep
                                                      Mystringtokeniser__tokenise__tokens.tokens__first))
                                                  (Standard__integer__rep.to_rep
                                                     Mystringtokeniser__tokenise__tokens.tokens__last) in
                                              (Array__Int__Mystringtokeniser__tokenextent.get
                                                 (Mystringtokeniser__tokenise__S2b.to_array
                                                    temp___237))
                                                (assert {
                                                   [#"mystringtokeniser.adb" 19 0 0]
                                                   [@GP_Id:18]
                                                   [@comment:              (Tokens(J).Start >= S'First and                       ^ mystringtokeniser.adb:19:23:VC_INDEX_CHECK]
                                                   [@vc:annotation]
                                                   [@GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                   [@GP_Sloc:mystringtokeniser.adb:19:23]
                                                   [@GP_Reason:VC_INDEX_CHECK]
                                                   (((Mystringtokeniser__tokenise__S2b.first
                                                        temp___237)
                                                       <= j) /\
                                                      (j
                                                         <= (Mystringtokeniser__tokenise__S2b.last
                                                               temp___237))) };
                                                 j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                       >= (Standard__string.first
                                             Mystringtokeniser__tokenise__s.s)))
                                   ((Standard__natural__rep.to_rep
                                       ((Mystringtokeniser__tokenextent.__split_fields
                                            (let temp___238 =
                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                      Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                  (Standard__integer__rep.to_rep
                                                     Mystringtokeniser__tokenise__tokens.tokens__first))
                                                 (Standard__integer__rep.to_rep
                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                   temp___238))
                                               (assert {
                                                  [#"mystringtokeniser.adb" 20 0 0]
                                                  [@GP_Id:19]
                                                  [@comment:                   Tokens(J).Length > 0) and then                           ^ mystringtokeniser.adb:20:27:VC_INDEX_CHECK]
                                                  [@GP_Sloc:mystringtokeniser.adb:20:27]
                                                  [@vc:annotation]
                                                  [@GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                  [@GP_Reason:VC_INDEX_CHECK]
                                                  (((Mystringtokeniser__tokenise__S2b.first
                                                       temp___238)
                                                      <= j) /\
                                                     (j
                                                        <= (Mystringtokeniser__tokenise__S2b.last
                                                              temp___238))) };
                                                j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                      > (0 : int)))
                                 &&
                                  (((Standard__natural__rep.to_rep
                                       ((Mystringtokeniser__tokenextent.__split_fields
                                            (let temp___239 =
                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                      Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                  (Standard__integer__rep.to_rep
                                                     Mystringtokeniser__tokenise__tokens.tokens__first))
                                                 (Standard__integer__rep.to_rep
                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                   temp___239))
                                               (assert {
                                                  [#"mystringtokeniser.adb" 21 0 0]
                                                  [@vc:annotation]
                                                  [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                    ^ mystringtokeniser.adb:21:20:VC_INDEX_CHECK]
                                                  [@GP_Sloc:mystringtokeniser.adb:21:20]
                                                  [@GP_Reason:VC_INDEX_CHECK]
                                                  [@GP_Id:20]
                                                  [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                                  (((Mystringtokeniser__tokenise__S2b.first
                                                       temp___239)
                                                      <= j) /\
                                                     (j
                                                        <= (Mystringtokeniser__tokenise__S2b.last
                                                              temp___239))) };
                                                j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                      - (1 : int))
                                     <= ([#"mystringtokeniser.adb" 21 0 0]
                                         [@GP_Sloc:mystringtokeniser.adb:21:42]
                                         [@vc:annotation]
                                         [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                          ^ mystringtokeniser.adb:21:42:VC_OVERFLOW_CHECK]
                                         [@GP_Reason:VC_OVERFLOW_CHECK]
                                         [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub]
                                         [@GP_Id:22]
                                         (Standard__integer.range_check_
                                            ((([#"mystringtokeniser.adb" 21 0 0]
                                               ());
                                              (Standard__string.last
                                                 Mystringtokeniser__tokenise__s.s))
                                               - (Standard__positive__rep.to_rep
                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                         (let temp___240 =
                                                            ((Mystringtokeniser__tokenise__S2b.of_array
                                                                (Mystringtokeniser__tokenise__tokens.tokens.
                                                                   Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__first))
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                          (Array__Int__Mystringtokeniser__tokenextent.get
                                                             (Mystringtokeniser__tokenise__S2b.to_array
                                                                temp___240))
                                                            (([#"mystringtokeniser.adb" 21 0 0]
                                                              assert {
                                                                [#"mystringtokeniser.adb" 21 0 0]
                                                                [#"mystringtokeniser.adb" 21 0 0]
                                                                [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                                   ^ mystringtokeniser.adb:21:51:VC_INDEX_CHECK]
                                                                [@vc:annotation]
                                                                [@GP_Reason:VC_INDEX_CHECK]
                                                                [@GP_Sloc:mystringtokeniser.adb:21:51]
                                                                [@GP_Id:21]
                                                                [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                                                (((Mystringtokeniser__tokenise__S2b.first
                                                                    temp___240)
                                                                    <= j) /\
                                                                   (j
                                                                    <= 
                                                                    (Mystringtokeniser__tokenise__S2b.last
                                                                    temp___240))) });
                                                             j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))) in
                              () in
                            ()
                          end)
                       else ());
                      (val _f : bool
                         ensures { ((result = True) <->
                                      (forall j : int.
                                         ((((Standard__integer__rep.to_rep
                                               Mystringtokeniser__tokenise__tokens.tokens__first)
                                              <= j) /\
                                             (j
                                                <= ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                                      - (1 : int)))) ->
                                            ((((Standard__positive__rep.to_rep
                                                  ((Mystringtokeniser__tokenextent.__split_fields
                                                       (let temp___241 =
                                                          ((Mystringtokeniser__tokenise__S2b.of_array
                                                              (Mystringtokeniser__tokenise__tokens.tokens.
                                                                 Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                             (Standard__integer__rep.to_rep
                                                                Mystringtokeniser__tokenise__tokens.tokens__first))
                                                            (Standard__integer__rep.to_rep
                                                               Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                        (Array__Int__Mystringtokeniser__tokenextent.get
                                                           (Mystringtokeniser__tokenise__S2b.to_array
                                                              temp___241))
                                                          j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                                 >= (Standard__string.first
                                                       Mystringtokeniser__tokenise__s.s)) /\
                                                ((Standard__natural__rep.to_rep
                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                         (let temp___242 =
                                                            ((Mystringtokeniser__tokenise__S2b.of_array
                                                                (Mystringtokeniser__tokenise__tokens.tokens.
                                                                   Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__first))
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                          (Array__Int__Mystringtokeniser__tokenextent.get
                                                             (Mystringtokeniser__tokenise__S2b.to_array
                                                                temp___242))
                                                            j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                   > (0 : int))) /\
                                               (((Standard__natural__rep.to_rep
                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                         (let temp___243 =
                                                            ((Mystringtokeniser__tokenise__S2b.of_array
                                                                (Mystringtokeniser__tokenise__tokens.tokens.
                                                                   Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__first))
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                          (Array__Int__Mystringtokeniser__tokenextent.get
                                                             (Mystringtokeniser__tokenise__S2b.to_array
                                                                temp___243))
                                                            j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                   - (1 : int))
                                                  <= ((Standard__string.last
                                                         Mystringtokeniser__tokenise__s.s)
                                                        - (Standard__positive__rep.to_rep
                                                             ((Mystringtokeniser__tokenextent.__split_fields
                                                                  (let temp___244 =
                                                                    ((Mystringtokeniser__tokenise__S2b.of_array
                                                                    (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                                   (Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    temp___244))
                                                                    j)).
                                                                Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))))) } in
                       _f) in
                    begin
                      ensures { true }
                      let _ =
                        let _ =
                          let temp___inv_235 =
                            ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                               = ([#"mystringtokeniser.adb" 23 0 0]
                                  [@comment:         pragma Loop_Invariant (OutIndex = Tokens'First + Count);                                                         ^ mystringtokeniser.adb:23:57:VC_OVERFLOW_CHECK]
                                  [@GP_Id:15]
                                  [@GP_Shape:L_1_while__pragargs__cmp__add]
                                  [@vc:annotation]
                                  [@GP_Reason:VC_OVERFLOW_CHECK]
                                  [@GP_Sloc:mystringtokeniser.adb:23:57]
                                  (Standard__integer.range_check_
                                     ((Standard__integer__rep.to_rep
                                         (([#"mystringtokeniser.adb" 23 0 0]
                                           (begin
                                              ensures { true }
                                              let _ =
                                                let _ =
                                                  ((Mystringtokeniser__tokenise__S2b.of_array
                                                      (Mystringtokeniser__tokenise__tokens.tokens.
                                                         Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__first))
                                                    (Standard__integer__rep.to_rep
                                                       Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                () in
                                              ()
                                            end));
                                          Mystringtokeniser__tokenise__tokens.tokens__first))
                                        + (Mystringtokeniser__tokenise__count.count.int__content))))) in
                          () in
                        () in
                      ()
                    end));
                  while True do
                    invariant LoopInvariant {
                      [#"mystringtokeniser.adb" 18 0 0]
                      [@comment:           (for all J in Tokens'First..OutIndex-1 =>             ^ mystringtokeniser.adb:18:13:VC_LOOP_INVARIANT]
                      [@GP_Reason:VC_LOOP_INVARIANT]
                      [@vc:annotation]
                      [@GP_Shape:L_1_while__pragargs__forall]
                      [@GP_Sloc:mystringtokeniser.adb:18:13]
                      [@GP_Id:23]
                      (forall j : int.
                         ((((Standard__integer__rep.to_rep
                               Mystringtokeniser__tokenise__tokens.tokens__first)
                              <= j) /\
                             (j
                                <= ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                      - (1 : int)))) ->
                            ((([@GP_Sloc:mystringtokeniser.adb:19:16]
                               [@GP_Pretty_Ada:902]
                               ((Standard__positive__rep.to_rep
                                   ((Mystringtokeniser__tokenextent.__split_fields
                                        (let temp___245 =
                                           ((Mystringtokeniser__tokenise__S2b.of_array
                                               (Mystringtokeniser__tokenise__tokens.tokens.
                                                  Array__Int__Mystringtokeniser__tokenextent.map__content))
                                              (Standard__integer__rep.to_rep
                                                 Mystringtokeniser__tokenise__tokens.tokens__first))
                                             (Standard__integer__rep.to_rep
                                                Mystringtokeniser__tokenise__tokens.tokens__last) in
                                         (Array__Int__Mystringtokeniser__tokenextent.get
                                            (Mystringtokeniser__tokenise__S2b.to_array
                                               temp___245))
                                           j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                  >= (Standard__string.first
                                        Mystringtokeniser__tokenise__s.s))) /\
                                ([@GP_Sloc:mystringtokeniser.adb:20:20]
                                 [@GP_Pretty_Ada:912]
                                 ((Standard__natural__rep.to_rep
                                     ((Mystringtokeniser__tokenextent.__split_fields
                                          (let temp___246 =
                                             ((Mystringtokeniser__tokenise__S2b.of_array
                                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                               (Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__last) in
                                           (Array__Int__Mystringtokeniser__tokenextent.get
                                              (Mystringtokeniser__tokenise__S2b.to_array
                                                 temp___246))
                                             j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                    > (0 : int)))) /\
                               ([@GP_Pretty_Ada:922]
                                [@GP_Sloc:mystringtokeniser.adb:21:13]
                                (((Standard__natural__rep.to_rep
                                     ((Mystringtokeniser__tokenextent.__split_fields
                                          (let temp___247 =
                                             ((Mystringtokeniser__tokenise__S2b.of_array
                                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                               (Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__last) in
                                           (Array__Int__Mystringtokeniser__tokenextent.get
                                              (Mystringtokeniser__tokenise__S2b.to_array
                                                 temp___247))
                                             j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                    - (1 : int))
                                   <= ((Standard__string.last
                                          Mystringtokeniser__tokenise__s.s)
                                         - (Standard__positive__rep.to_rep
                                              ((Mystringtokeniser__tokenextent.__split_fields
                                                   (let temp___248 =
                                                      ((Mystringtokeniser__tokenise__S2b.of_array
                                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                    (Array__Int__Mystringtokeniser__tokenextent.get
                                                       (Mystringtokeniser__tokenise__S2b.to_array
                                                          temp___248))
                                                      j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))))) }
                    invariant LoopInvariant {
                      [#"mystringtokeniser.adb" 23 0 0]
                      [@GP_Sloc:mystringtokeniser.adb:23:33]
                      [@GP_Reason:VC_LOOP_INVARIANT]
                      [@GP_Id:16]
                      [@vc:annotation]
                      [@comment:         pragma Loop_Invariant (OutIndex = Tokens'First + Count);                                 ^ mystringtokeniser.adb:23:33:VC_LOOP_INVARIANT]
                      [@GP_Shape:L_1_while__pragargs__cmp]
                      [@GP_Sloc:mystringtokeniser.adb:23:33]
                      [@GP_Pretty_Ada:936]
                      ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                         = ((Standard__integer__rep.to_rep
                               Mystringtokeniser__tokenise__tokens.tokens__first)
                              + (Mystringtokeniser__tokenise__count.count.int__content))) }
                    ([@GNAT-comment:gnat_ast_to_ptree: code after the loop invariant]
                     (([@GNAT-comment:Assume implicit invariants from the loop mystringtokeniser.adb:16]
                       ());
                      assume {
                        (Boolean.andb
                           ((((((((((true /\
                                       (forall temp___231 : int.
                                          if (((Mystringtokeniser__tokenise__S2b.first
                                                  (((Mystringtokeniser__tokenise__S2b.of_array
                                                       (Mystringtokeniser__tokenise__tokens.tokens.
                                                          Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__first))
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__last)))
                                                 <= temp___231) /\
                                                (temp___231
                                                   <= (Mystringtokeniser__tokenise__S2b.last
                                                         (((Mystringtokeniser__tokenise__S2b.of_array
                                                              (Mystringtokeniser__tokenise__tokens.tokens.
                                                                 Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                             (Standard__integer__rep.to_rep
                                                                Mystringtokeniser__tokenise__tokens.tokens__first))
                                                            (Standard__integer__rep.to_rep
                                                               Mystringtokeniser__tokenise__tokens.tokens__last))))) then
                                            (((((Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                                                   ((Array__Int__Mystringtokeniser__tokenextent.get
                                                       (Mystringtokeniser__tokenise__S2b.to_array
                                                          (((Mystringtokeniser__tokenise__S2b.of_array
                                                               (Mystringtokeniser__tokenise__tokens.tokens.
                                                                  Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                              (Standard__integer__rep.to_rep
                                                                 Mystringtokeniser__tokenise__tokens.tokens__first))
                                                             (Standard__integer__rep.to_rep
                                                                Mystringtokeniser__tokenise__tokens.tokens__last))))
                                                      temp___231))
                                                  True)
                                                 False)
                                                True)
                                               True)
                                          else true)) /\
                                      (true /\ true)) /\
                                     (((((Standard__natural___axiom.dynamic_invariant
                                            (Mystringtokeniser__tokenise__count.count.int__content))
                                           False)
                                          True)
                                         True)
                                        True)) /\
                                    (true /\ true)) /\
                                   (((((Standard__positive___axiom.dynamic_invariant
                                          (Mystringtokeniser__tokenise__index.index.int__content))
                                         False)
                                        True)
                                       True)
                                      True)) /\
                                  (true /\ true)) /\
                                 (((((Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                                        { Mystringtokeniser__tokenextent.__split_fields =
                                            (Mystringtokeniser__tokenextent.__split_fields__content
                                                Mystringtokeniser__tokenise__extent.extent__split_fields) })
                                       False)
                                      True)
                                     True)
                                    True)) /\
                                (true /\ true)) /\
                               (((((Standard__integer___axiom.dynamic_invariant
                                      (Mystringtokeniser__tokenise__outindex.outindex.int__content))
                                     True)
                                    True)
                                   True)
                                  True)) /\
                              (true /\ true)))
                          ((((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                               <= (Standard__integer__rep.to_rep
                                     Mystringtokeniser__tokenise__tokens.tokens__last)) /\
                              ((Mystringtokeniser__tokenise__index.index.int__content)
                                 <= (Standard__string.last
                                       Mystringtokeniser__tokenise__s.s))) /\
                             ((Mystringtokeniser__tokenise__count.count.int__content)
                                < ((Integer.length
                                      (Standard__integer__rep.to_rep
                                         Mystringtokeniser__tokenise__tokens.tokens__first))
                                     (Standard__integer__rep.to_rep
                                        Mystringtokeniser__tokenise__tokens.tokens__last)))) };
                      ([@GNAT-comment:Continuation of loop after loop invariant and variant]
                       ());
                      ([@GP_Sloc:mystringtokeniser.adb:26:87]
                       [#"mystringtokeniser.adb" 26 0 0]
                       (([@GNAT-comment:Translation of an Ada loop from mystringtokeniser.adb:26]
                         ());
                        (if (((Boolean.andb
                                 ((Mystringtokeniser__tokenise__index.index.int__content)
                                    >= (([#"mystringtokeniser.adb" 26 0 0] ());
                                        (Standard__string.first
                                           Mystringtokeniser__tokenise__s.s))))
                                ((Mystringtokeniser__tokenise__index.index.int__content)
                                   < (([#"mystringtokeniser.adb" 26 0 0] ());
                                      (Standard__string.last
                                         Mystringtokeniser__tokenise__s.s))))
                              &&
                               (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                  (Standard__character__rep.to_rep
                                     ((Array__Int__Standard__character.get
                                         (Standard__string.to_array
                                            Mystringtokeniser__tokenise__s.s))
                                        (([#"mystringtokeniser.adb" 26 0 0]
                                          assert {
                                            [#"mystringtokeniser.adb" 26 0 0]
                                            [#"mystringtokeniser.adb" 26 0 0]
                                            [@GP_Sloc:mystringtokeniser.adb:26:79]
                                            [@vc:annotation]
                                            [@GP_Shape:L_1_while__L_2_while__andthen__call_is_whitespace__ixdcomp]
                                            [@GP_Reason:VC_INDEX_CHECK]
                                            [@comment:         while (Index >= S'First and Index < S'Last) and then Is_Whitespace(S(Index)) loop                                                                               ^ mystringtokeniser.adb:26:79:VC_INDEX_CHECK]
                                            [@GP_Id:2]
                                            (((Standard__string.first
                                                 Mystringtokeniser__tokenise__s.s)
                                                <= (Mystringtokeniser__tokenise__index.index.int__content)) /\
                                               ((Mystringtokeniser__tokenise__index.index.int__content)
                                                  <= (Standard__string.last
                                                        Mystringtokeniser__tokenise__s.s))) });
                                         (Mystringtokeniser__tokenise__index.index.int__content)))))) then
                           (try
                              ([@GNAT-comment:While loop translating the Ada loop from mystringtokeniser.adb:26]
                               ());
                              ([#"mystringtokeniser.adb" 26 0 0]
                               [#"mystringtokeniser.adb" 26 0 0]
                               (([@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                                 ());
                                while True do
                                  ([@GNAT-comment:gnat_ast_to_ptree: code after the loop invariant]
                                   (([@GNAT-comment:Assume implicit invariants from the loop mystringtokeniser.adb:26]
                                     ());
                                    ([#"mystringtokeniser.adb" 26 0 0]
                                     assume {
                                       [#"mystringtokeniser.adb" 26 0 0]
                                       ((Boolean.andb
                                           ((true /\
                                               (((((Standard__positive___axiom.dynamic_invariant
                                                      (Mystringtokeniser__tokenise__index.index.int__content))
                                                     False)
                                                    True)
                                                   True)
                                                  True)) /\
                                              (true /\ true)))
                                          ((((Mystringtokeniser__tokenise__index.index.int__content)
                                               >= (Standard__string.first
                                                     Mystringtokeniser__tokenise__s.s)) /\
                                              ((Mystringtokeniser__tokenise__index.index.int__content)
                                                 < (Standard__string.last
                                                      Mystringtokeniser__tokenise__s.s))) /\
                                             ((epsilon temp___result_213: bool.
                                                 ((temp___result_213
                                                     = (Mystringtokeniser__is_whitespace.is_whitespace
                                                          (Standard__character__rep.to_rep
                                                             ((Array__Int__Standard__character.get
                                                                 (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                (Mystringtokeniser__tokenise__index.index.int__content))))) /\
                                                    ((Mystringtokeniser__is_whitespace.is_whitespace__function_guard
                                                        temp___result_213)
                                                       (Standard__character__rep.to_rep
                                                          ((Array__Int__Standard__character.get
                                                              (Standard__string.to_array
                                                                 Mystringtokeniser__tokenise__s.s))
                                                             (Mystringtokeniser__tokenise__index.index.int__content))))))
                                                = True))) });
                                    ([@GNAT-comment:Continuation of loop after loop invariant and variant]
                                     ());
                                    ([@GP_Sloc:mystringtokeniser.adb:27:13]
                                     [#"mystringtokeniser.adb" 27 0 0] ());
                                    ([@GP_Sloc:mystringtokeniser.adb:27:22]
                                     [#"mystringtokeniser.adb" 27 0 0] ());
                                    ([@GP_Sloc:mystringtokeniser.adb:27:19]
                                     [#"mystringtokeniser.adb" 27 0 0]
                                     [#"mystringtokeniser.adb" 27 0 0]
                                     (Mystringtokeniser__tokenise__index.index.int__content <-
                                        ([#"mystringtokeniser.adb" 27 0 0]
                                         [@GP_Sloc:mystringtokeniser.adb:27:28]
                                         [@GP_Shape:L_1_while__L_2_while__index_assign__add]
                                         [@vc:annotation]
                                         [@GP_Reason:VC_OVERFLOW_CHECK]
                                         [@GP_Id:1]
                                         [@comment:            Index := Index + 1;                            ^ mystringtokeniser.adb:27:28:VC_OVERFLOW_CHECK]
                                         (Standard__integer.range_check_
                                            ((Mystringtokeniser__tokenise__index.index.int__content)
                                               + (1 : int))))));
                                    ([@GNAT-comment:Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:26]
                                     ());
                                    (if (not (((Boolean.andb
                                                  ((Mystringtokeniser__tokenise__index.index.int__content)
                                                     >= (Standard__string.first
                                                           Mystringtokeniser__tokenise__s.s)))
                                                 ((Mystringtokeniser__tokenise__index.index.int__content)
                                                    < (Standard__string.last
                                                         Mystringtokeniser__tokenise__s.s)))
                                               &&
                                                (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                                   (Standard__character__rep.to_rep
                                                      ((Array__Int__Standard__character.get
                                                          (Standard__string.to_array
                                                             Mystringtokeniser__tokenise__s.s))
                                                         (assert {
                                                            [#"mystringtokeniser.adb" 26 0 0]
                                                            [@GP_Sloc:mystringtokeniser.adb:26:79]
                                                            [@vc:annotation]
                                                            [@GP_Shape:L_1_while__L_2_while__andthen__call_is_whitespace__ixdcomp]
                                                            [@GP_Reason:VC_INDEX_CHECK]
                                                            [@comment:         while (Index >= S'First and Index < S'Last) and then Is_Whitespace(S(Index)) loop                                                                               ^ mystringtokeniser.adb:26:79:VC_INDEX_CHECK]
                                                            [@GP_Id:2]
                                                            (((Standard__string.first
                                                                 Mystringtokeniser__tokenise__s.s)
                                                                <= (Mystringtokeniser__tokenise__index.index.int__content)) /\
                                                               ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                  <= 
                                                                  (Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s))) };
                                                          (Mystringtokeniser__tokenise__index.index.int__content))))))) then
                                       (raise Mystringtokeniser__tokenise__L_2.L_2)
                                     else ())));
                                  ([@GNAT-comment:gnat_ast_to_ptree: code before the loop invariant]
                                   [@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                                   ());
                                  ([@GNAT-comment:gnat_ast_to_ptree: code checking the variants]
                                   ())
                                done))
                            with Mystringtokeniser__tokenise__L_2.L_2 -> ()
                            end)
                         else ())));
                      ([@GP_Sloc:mystringtokeniser.adb:29:14]
                       [#"mystringtokeniser.adb" 29 0 0] ());
                      ([@GP_Sloc:mystringtokeniser.adb:29:35]
                       [#"mystringtokeniser.adb" 29 0 0] ());
                      ([@GP_Sloc:mystringtokeniser.adb:29:10]
                       [#"mystringtokeniser.adb" 29 0 0]
                       (if (([#"mystringtokeniser.adb" 29 0 0]
                             [#"mystringtokeniser.adb" 29 0 0]
                             (([@branch_id=967] Main.spark__branch).bool__content <-
                                (((Boolean.andb
                                     ((Mystringtokeniser__tokenise__index.index.int__content)
                                        >= (([#"mystringtokeniser.adb" 29 0 0]
                                             ());
                                            (Standard__string.first
                                               Mystringtokeniser__tokenise__s.s))))
                                    ((Mystringtokeniser__tokenise__index.index.int__content)
                                       <= (([#"mystringtokeniser.adb" 29 0 0]
                                            ());
                                           (Standard__string.last
                                              Mystringtokeniser__tokenise__s.s))))
                                  &&
                                   (not (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                           (Standard__character__rep.to_rep
                                              ((Array__Int__Standard__character.get
                                                  (Standard__string.to_array
                                                     Mystringtokeniser__tokenise__s.s))
                                                 (([#"mystringtokeniser.adb" 29 0 0]
                                                   assert {
                                                     [#"mystringtokeniser.adb" 29 0 0]
                                                     [#"mystringtokeniser.adb" 29 0 0]
                                                     [@GP_Id:14]
                                                     [@GP_Sloc:mystringtokeniser.adb:29:81]
                                                     [@vc:annotation]
                                                     [@comment:         if (Index >= S'First and Index <= S'Last) and then not Is_Whitespace(S(Index)) then                                                                                 ^ mystringtokeniser.adb:29:81:VC_INDEX_CHECK]
                                                     [@GP_Shape:L_1_while__if__andthen__not__call_is_whitespace__ixdcomp]
                                                     [@GP_Reason:VC_INDEX_CHECK]
                                                     (((Standard__string.first
                                                          Mystringtokeniser__tokenise__s.s)
                                                         <= (Mystringtokeniser__tokenise__index.index.int__content)) /\
                                                        ((Mystringtokeniser__tokenise__index.index.int__content)
                                                           <= (Standard__string.last
                                                                 Mystringtokeniser__tokenise__s.s))) });
                                                  (Mystringtokeniser__tokenise__index.index.int__content)))))))));
                            (([@branch_id=967] Main.spark__branch).bool__content)) then
                          (([@GP_Sloc:mystringtokeniser.adb:31:13]
                            [#"mystringtokeniser.adb" 31 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:31:29]
                            [#"mystringtokeniser.adb" 31 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:31:26]
                            [#"mystringtokeniser.adb" 31 0 0]
                            (let temp___216 =
                               let temp___215 =
                                 { Mystringtokeniser__tokenextent.__split_fields =
                                     (Mystringtokeniser__tokenextent.__split_fields__content
                                         Mystringtokeniser__tokenise__extent.extent__split_fields) } in
                               ([#"mystringtokeniser.adb" 31 0 0]
                                (begin
                                   ensures { true }
                                   let _ =
                                     let _ =
                                       (Mystringtokeniser__tokenextent.__split_fields
                                           temp___215).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start in
                                     () in
                                   ()
                                 end));
                               ({ temp___215 with
                                  Mystringtokeniser__tokenextent.__split_fields =
                                    ({ (Mystringtokeniser__tokenextent.__split_fields
                                           temp___215) with
                                       Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start =
                                         (Standard__positive__rep.of_rep
                                            (Mystringtokeniser__tokenise__index.index.int__content)) }) }) in
                             [#"mystringtokeniser.adb" 31 0 0]
                             (Mystringtokeniser__tokenise__extent.extent__split_fields.
                                Mystringtokeniser__tokenextent.__split_fields__content <-
                                (Mystringtokeniser__tokenextent.__split_fields
                                    temp___216))));
                           ([@GP_Sloc:mystringtokeniser.adb:32:13]
                            [#"mystringtokeniser.adb" 32 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:32:27]
                            [#"mystringtokeniser.adb" 32 0 0]
                            (let temp___219 =
                               let temp___218 =
                                 { Mystringtokeniser__tokenextent.__split_fields =
                                     (Mystringtokeniser__tokenextent.__split_fields__content
                                         Mystringtokeniser__tokenise__extent.extent__split_fields) } in
                               ([#"mystringtokeniser.adb" 32 0 0]
                                (begin
                                   ensures { true }
                                   let _ =
                                     let _ =
                                       (Mystringtokeniser__tokenextent.__split_fields
                                           temp___218).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length in
                                     () in
                                   ()
                                 end));
                               ({ temp___218 with
                                  Mystringtokeniser__tokenextent.__split_fields =
                                    ({ (Mystringtokeniser__tokenextent.__split_fields
                                           temp___218) with
                                       Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length =
                                         (0 : Standard__natural.natural) }) }) in
                             [#"mystringtokeniser.adb" 32 0 0]
                             (Mystringtokeniser__tokenise__extent.extent__split_fields.
                                Mystringtokeniser__tokenextent.__split_fields__content <-
                                (Mystringtokeniser__tokenextent.__split_fields
                                    temp___219))));
                           ([@GP_Sloc:mystringtokeniser.adb:35:185]
                            [#"mystringtokeniser.adb" 35 0 0]
                            (([@GNAT-comment:Translation of an Ada loop from mystringtokeniser.adb:35]
                              ());
                             (if (((([#"mystringtokeniser.adb" 35 0 0]
                                     [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__cmp__sub]
                                     [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                 ^ mystringtokeniser.adb:35:33:VC_OVERFLOW_CHECK]
                                     [@vc:annotation]
                                     [@GP_Reason:VC_OVERFLOW_CHECK]
                                     [@GP_Id:4]
                                     [@GP_Sloc:mystringtokeniser.adb:35:33]
                                     (Standard__integer.range_check_
                                        ((2147483647 : int)
                                           - (Standard__natural__rep.to_rep
                                                ((Mystringtokeniser__tokenextent.__split_fields
                                                     { Mystringtokeniser__tokenextent.__split_fields =
                                                         (Mystringtokeniser__tokenextent.__split_fields__content
                                                             Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                   Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                      >= (Mystringtokeniser__tokenise__index.index.int__content))
                                    &&
                                     ((Boolean.andb
                                         (([#"mystringtokeniser.adb" 35 0 0]
                                           [@vc:annotation]
                                           [@GP_Reason:VC_OVERFLOW_CHECK]
                                           [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                         ^ mystringtokeniser.adb:35:73:VC_OVERFLOW_CHECK]
                                           [@GP_Sloc:mystringtokeniser.adb:35:73]
                                           [@GP_Id:5]
                                           [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add]
                                           (Standard__integer.range_check_
                                              ((Mystringtokeniser__tokenise__index.index.int__content)
                                                 + (Standard__natural__rep.to_rep
                                                      ((Mystringtokeniser__tokenextent.__split_fields
                                                           { Mystringtokeniser__tokenextent.__split_fields =
                                                               (Mystringtokeniser__tokenextent.__split_fields__content
                                                                   Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                         Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                            >= (Standard__string.first
                                                  Mystringtokeniser__tokenise__s.s)))
                                        (([#"mystringtokeniser.adb" 35 0 0]
                                          [@vc:annotation]
                                          [@GP_Reason:VC_OVERFLOW_CHECK]
                                          [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                            ^ mystringtokeniser.adb:35:108:VC_OVERFLOW_CHECK]
                                          [@GP_Sloc:mystringtokeniser.adb:35:108]
                                          [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add]
                                          [@GP_Id:6]
                                          (Standard__integer.range_check_
                                             ((Mystringtokeniser__tokenise__index.index.int__content)
                                                + (Standard__natural__rep.to_rep
                                                     ((Mystringtokeniser__tokenextent.__split_fields
                                                          { Mystringtokeniser__tokenextent.__split_fields =
                                                              (Mystringtokeniser__tokenextent.__split_fields__content
                                                                  Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                        Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                           <= (Standard__string.last
                                                 Mystringtokeniser__tokenise__s.s))))
                                   &&
                                    (not (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                            (Standard__character__rep.to_rep
                                               ((Array__Int__Standard__character.get
                                                   (Standard__string.to_array
                                                      Mystringtokeniser__tokenise__s.s))
                                                  (let temp___224 =
                                                     [#"mystringtokeniser.adb" 35 0 0]
                                                     [@GP_Sloc:mystringtokeniser.adb:35:168]
                                                     [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                                                                                        ^ mystringtokeniser.adb:35:168:VC_OVERFLOW_CHECK]
                                                     [@vc:annotation]
                                                     [@GP_Reason:VC_OVERFLOW_CHECK]
                                                     [@GP_Id:7]
                                                     [@GP_Shape:L_1_while__if__L_3_while__andthen__not__call_is_whitespace__ixdcomp__add]
                                                     (Standard__integer.range_check_
                                                        ((Mystringtokeniser__tokenise__index.index.int__content)
                                                           + (Standard__natural__rep.to_rep
                                                                ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                   Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))) in
                                                   assert {
                                                     [#"mystringtokeniser.adb" 35 0 0]
                                                     [@GP_Sloc:mystringtokeniser.adb:35:168]
                                                     [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                                                                                        ^ mystringtokeniser.adb:35:168:VC_INDEX_CHECK]
                                                     [@vc:annotation]
                                                     [@GP_Reason:VC_INDEX_CHECK]
                                                     [@GP_Id:8]
                                                     [@GP_Shape:L_1_while__if__L_3_while__andthen__not__call_is_whitespace__ixdcomp__add]
                                                     (((Standard__string.first
                                                          Mystringtokeniser__tokenise__s.s)
                                                         <= temp___224) /\
                                                        (temp___224
                                                           <= (Standard__string.last
                                                                 Mystringtokeniser__tokenise__s.s))) };
                                                   temp___224)))))) then
                                (try
                                   let temp___loop_entry_223 =
                                     { Mystringtokeniser__tokenextent.__split_fields =
                                         (Mystringtokeniser__tokenextent.__split_fields__content
                                             Mystringtokeniser__tokenise__extent.extent__split_fields) } in
                                   ([@GNAT-comment:While loop translating the Ada loop from mystringtokeniser.adb:35]
                                    ());
                                   ([#"mystringtokeniser.adb" 35 0 0]
                                    [#"mystringtokeniser.adb" 35 0 0]
                                    (([@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                                      ());
                                     while True do
                                       ([@GNAT-comment:gnat_ast_to_ptree: code after the loop invariant]
                                        (([@GNAT-comment:Assume implicit invariants from the loop mystringtokeniser.adb:35]
                                          ());
                                         ([#"mystringtokeniser.adb" 35 0 0]
                                          assume {
                                            [#"mystringtokeniser.adb" 35 0 0]
                                            ((Boolean.andb
                                                ((true /\
                                                    (((((Mystringtokeniser__tokenextent___axiom.dynamic_invariant
                                                           { Mystringtokeniser__tokenextent.__split_fields =
                                                               (Mystringtokeniser__tokenextent.__split_fields__content
                                                                   Mystringtokeniser__tokenise__extent.extent__split_fields) })
                                                          False)
                                                         True)
                                                        True)
                                                       True)) /\
                                                   (true /\
                                                      (((Mystringtokeniser__tokenextent.__split_fields
                                                            { Mystringtokeniser__tokenextent.__split_fields =
                                                                (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                          Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)
                                                         = ((Mystringtokeniser__tokenextent.__split_fields
                                                                temp___loop_entry_223).
                                                              Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))
                                               (((((2147483647 : int)
                                                     - (Standard__natural__rep.to_rep
                                                          ((Mystringtokeniser__tokenextent.__split_fields
                                                               { Mystringtokeniser__tokenextent.__split_fields =
                                                                   (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                             Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))
                                                    >= (Mystringtokeniser__tokenise__index.index.int__content)) /\
                                                   ((((Mystringtokeniser__tokenise__index.index.int__content)
                                                        + (Standard__natural__rep.to_rep
                                                             ((Mystringtokeniser__tokenextent.__split_fields
                                                                  { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))
                                                       >= (Standard__string.first
                                                             Mystringtokeniser__tokenise__s.s)) /\
                                                      (((Mystringtokeniser__tokenise__index.index.int__content)
                                                          + (Standard__natural__rep.to_rep
                                                               ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                  Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))
                                                         <= (Standard__string.last
                                                               Mystringtokeniser__tokenise__s.s)))) /\
                                                  (not ((epsilon temp___result_225: bool.
                                                           ((temp___result_225
                                                               = (Mystringtokeniser__is_whitespace.is_whitespace
                                                                    (Standard__character__rep.to_rep
                                                                    ((Array__Int__Standard__character.get
                                                                    (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                    ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                    + (Standard__natural__rep.to_rep
                                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))))))) /\
                                                              ((Mystringtokeniser__is_whitespace.is_whitespace__function_guard
                                                                  temp___result_225)
                                                                 (Standard__character__rep.to_rep
                                                                    ((Array__Int__Standard__character.get
                                                                    (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                    ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                    + (Standard__natural__rep.to_rep
                                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))))))))
                                                          = True)))) });
                                         ([@GNAT-comment:Continuation of loop after loop invariant and variant]
                                          ());
                                         ([@GP_Sloc:mystringtokeniser.adb:36:16]
                                          [#"mystringtokeniser.adb" 36 0 0]
                                          ());
                                         ([@GP_Sloc:mystringtokeniser.adb:36:33]
                                          [#"mystringtokeniser.adb" 36 0 0]
                                          ());
                                         ([@GP_Sloc:mystringtokeniser.adb:36:30]
                                          [#"mystringtokeniser.adb" 36 0 0]
                                          (let temp___222 =
                                             let temp___221 =
                                               { Mystringtokeniser__tokenextent.__split_fields =
                                                   (Mystringtokeniser__tokenextent.__split_fields__content
                                                       Mystringtokeniser__tokenise__extent.extent__split_fields) } in
                                             ([#"mystringtokeniser.adb" 36 0 0]
                                              (begin
                                                 ensures { true }
                                                 let _ =
                                                   let _ =
                                                     (Mystringtokeniser__tokenextent.__split_fields
                                                         temp___221).
                                                       Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length in
                                                   () in
                                                 ()
                                               end));
                                             ({ temp___221 with
                                                Mystringtokeniser__tokenextent.__split_fields =
                                                  ({ (Mystringtokeniser__tokenextent.__split_fields
                                                         temp___221) with
                                                     Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length =
                                                       (Standard__natural__rep.of_rep
                                                          ([#"mystringtokeniser.adb" 36 0 0]
                                                           [@GP_Sloc:mystringtokeniser.adb:36:47]
                                                           [@GP_Shape:L_1_while__if__L_3_while__extent_assign__add]
                                                           [@comment:               Extent.Length := Extent.Length + 1;                                               ^ mystringtokeniser.adb:36:47:VC_OVERFLOW_CHECK]
                                                           [@vc:annotation]
                                                           [@GP_Reason:VC_OVERFLOW_CHECK]
                                                           [@GP_Id:3]
                                                           (Standard__integer.range_check_
                                                              ((Standard__natural__rep.to_rep
                                                                  ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                                 + (1 : int))))) }) }) in
                                           Mystringtokeniser__tokenise__extent.extent__split_fields.
                                             Mystringtokeniser__tokenextent.__split_fields__content <-
                                             (Mystringtokeniser__tokenextent.__split_fields
                                                 temp___222)));
                                         ([@GNAT-comment:Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:35]
                                          ());
                                         (if (not (((([#"mystringtokeniser.adb" 35 0 0]
                                                      [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__cmp__sub]
                                                      [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                 ^ mystringtokeniser.adb:35:33:VC_OVERFLOW_CHECK]
                                                      [@vc:annotation]
                                                      [@GP_Reason:VC_OVERFLOW_CHECK]
                                                      [@GP_Id:4]
                                                      [@GP_Sloc:mystringtokeniser.adb:35:33]
                                                      (Standard__integer.range_check_
                                                         ((2147483647 : int)
                                                            - (Standard__natural__rep.to_rep
                                                                 ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                       >= (Mystringtokeniser__tokenise__index.index.int__content))
                                                     &&
                                                      ((Boolean.andb
                                                          (([#"mystringtokeniser.adb" 35 0 0]
                                                            [@vc:annotation]
                                                            [@GP_Reason:VC_OVERFLOW_CHECK]
                                                            [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                         ^ mystringtokeniser.adb:35:73:VC_OVERFLOW_CHECK]
                                                            [@GP_Sloc:mystringtokeniser.adb:35:73]
                                                            [@GP_Id:5]
                                                            [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add]
                                                            (Standard__integer.range_check_
                                                               ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                  + (Standard__natural__rep.to_rep
                                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                             >= (Standard__string.first
                                                                   Mystringtokeniser__tokenise__s.s)))
                                                         (([#"mystringtokeniser.adb" 35 0 0]
                                                           [@vc:annotation]
                                                           [@GP_Reason:VC_OVERFLOW_CHECK]
                                                           [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                            ^ mystringtokeniser.adb:35:108:VC_OVERFLOW_CHECK]
                                                           [@GP_Sloc:mystringtokeniser.adb:35:108]
                                                           [@GP_Shape:L_1_while__if__L_3_while__andthen__andthen__and__cmp__add]
                                                           [@GP_Id:6]
                                                           (Standard__integer.range_check_
                                                              ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                 + (Standard__natural__rep.to_rep
                                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                                            <= (Standard__string.last
                                                                  Mystringtokeniser__tokenise__s.s))))
                                                    &&
                                                     (not (Mystringtokeniser__is_whitespace___axiom.is_whitespace
                                                             (Standard__character__rep.to_rep
                                                                ((Array__Int__Standard__character.get
                                                                    (Standard__string.to_array
                                                                    Mystringtokeniser__tokenise__s.s))
                                                                   (let temp___224 =
                                                                    [#"mystringtokeniser.adb" 35 0 0]
                                                                    [@GP_Sloc:mystringtokeniser.adb:35:168]
                                                                    [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                                                                                        ^ mystringtokeniser.adb:35:168:VC_OVERFLOW_CHECK]
                                                                    [@vc:annotation]
                                                                    [@GP_Reason:VC_OVERFLOW_CHECK]
                                                                    [@GP_Id:7]
                                                                    [@GP_Shape:L_1_while__if__L_3_while__andthen__not__call_is_whitespace__ixdcomp__add]
                                                                    (Standard__integer.range_check_
                                                                    ((Mystringtokeniser__tokenise__index.index.int__content)
                                                                    + (Standard__natural__rep.to_rep
                                                                    ((Mystringtokeniser__tokenextent.__split_fields
                                                                    { Mystringtokeniser__tokenextent.__split_fields =
                                                                    (Mystringtokeniser__tokenextent.__split_fields__content
                                                                    Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                                    Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))) in
                                                                    assert {
                                                                    [#"mystringtokeniser.adb" 35 0 0]
                                                                    [@GP_Sloc:mystringtokeniser.adb:35:168]
                                                                    [@comment:            while Positive'Last - Extent.Length >= Index and then (Index+Extent.Length >= S'First and Index+Extent.Length <= S'Last) and then not Is_Whitespace(S(Index+Extent.Length)) loop                                                                                                                                                                        ^ mystringtokeniser.adb:35:168:VC_INDEX_CHECK]
                                                                    [@vc:annotation]
                                                                    [@GP_Reason:VC_INDEX_CHECK]
                                                                    [@GP_Id:8]
                                                                    [@GP_Shape:L_1_while__if__L_3_while__andthen__not__call_is_whitespace__ixdcomp__add]
                                                                    (((Standard__string.first
                                                                    Mystringtokeniser__tokenise__s.s)
                                                                    <= temp___224) /\
                                                                    (temp___224
                                                                    <= (Standard__string.last
                                                                    Mystringtokeniser__tokenise__s.s))) };
                                                                    temp___224))))))) then
                                            (raise Mystringtokeniser__tokenise__L_3.L_3)
                                          else ())));
                                       ([@GNAT-comment:gnat_ast_to_ptree: code before the loop invariant]
                                        [@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                                        ());
                                       ([@GNAT-comment:gnat_ast_to_ptree: code checking the variants]
                                        ())
                                     done))
                                 with
                                   Mystringtokeniser__tokenise__L_3.L_3 ->
                                   ()
                                 end)
                              else ())));
                           ([@GP_Sloc:mystringtokeniser.adb:39:20]
                            [#"mystringtokeniser.adb" 39 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:39:33]
                            [#"mystringtokeniser.adb" 39 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:39:30]
                            [#"mystringtokeniser.adb" 39 0 0]
                            [#"mystringtokeniser.adb" 39 0 0]
                            (Mystringtokeniser__tokenise__tokens.tokens.
                               Array__Int__Mystringtokeniser__tokenextent.map__content <-
                               (Mystringtokeniser__tokenise__S2b.to_array
                                  (let temp___227 =
                                     ((Mystringtokeniser__tokenise__S2b.of_array
                                         (Mystringtokeniser__tokenise__tokens.tokens.
                                            Array__Int__Mystringtokeniser__tokenextent.map__content))
                                        (Standard__integer__rep.to_rep
                                           Mystringtokeniser__tokenise__tokens.tokens__first))
                                       (Standard__integer__rep.to_rep
                                          Mystringtokeniser__tokenise__tokens.tokens__last) in
                                   { (((Mystringtokeniser__tokenise__S2b.of_array
                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                         (Standard__integer__rep.to_rep
                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                        (Standard__integer__rep.to_rep
                                           Mystringtokeniser__tokenise__tokens.tokens__last)) with
                                     Mystringtokeniser__tokenise__S2b.elts =
                                       (((Array__Int__Mystringtokeniser__tokenextent.set
                                            (Mystringtokeniser__tokenise__S2b.to_array
                                               (((Mystringtokeniser__tokenise__S2b.of_array
                                                    (Mystringtokeniser__tokenise__tokens.tokens.
                                                       Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                   (Standard__integer__rep.to_rep
                                                      Mystringtokeniser__tokenise__tokens.tokens__first))
                                                  (Standard__integer__rep.to_rep
                                                     Mystringtokeniser__tokenise__tokens.tokens__last))))
                                           (([#"mystringtokeniser.adb" 39 0 0]
                                             assert {
                                               [#"mystringtokeniser.adb" 39 0 0]
                                               [#"mystringtokeniser.adb" 39 0 0]
                                               [@GP_Shape:L_1_while__if__tokens_assign__ixdcomp]
                                               [@vc:annotation]
                                               [@GP_Reason:VC_INDEX_CHECK]
                                               [@GP_Sloc:mystringtokeniser.adb:39:20]
                                               [@comment:            Tokens(OutIndex) := Extent;                    ^ mystringtokeniser.adb:39:20:VC_INDEX_CHECK]
                                               [@GP_Id:9]
                                               (((Mystringtokeniser__tokenise__S2b.first
                                                    temp___227)
                                                   <= (Mystringtokeniser__tokenise__outindex.outindex.int__content)) /\
                                                  ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                                     <= (Mystringtokeniser__tokenise__S2b.last
                                                           temp___227))) });
                                            (Mystringtokeniser__tokenise__outindex.outindex.int__content)))
                                          { Mystringtokeniser__tokenextent.__split_fields =
                                              (Mystringtokeniser__tokenextent.__split_fields__content
                                                  Mystringtokeniser__tokenise__extent.extent__split_fields) }) }))));
                           ([@GP_Sloc:mystringtokeniser.adb:40:19]
                            [#"mystringtokeniser.adb" 40 0 0]
                            [#"mystringtokeniser.adb" 40 0 0]
                            (Mystringtokeniser__tokenise__count.count.int__content <-
                               ([#"mystringtokeniser.adb" 40 0 0]
                                [@GP_Id:10]
                                [@GP_Shape:L_1_while__if__count_assign__add]
                                [@vc:annotation]
                                [@GP_Sloc:mystringtokeniser.adb:40:28]
                                [@GP_Reason:VC_OVERFLOW_CHECK]
                                [@comment:            Count := Count + 1;                            ^ mystringtokeniser.adb:40:28:VC_OVERFLOW_CHECK]
                                (Standard__integer.range_check_
                                   ((Mystringtokeniser__tokenise__count.count.int__content)
                                      + (1 : int))))));
                           ([@GP_Sloc:mystringtokeniser.adb:43:17]
                            [#"mystringtokeniser.adb" 43 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:43:13]
                            [#"mystringtokeniser.adb" 43 0 0]
                            (if (([#"mystringtokeniser.adb" 43 0 0]
                                  [#"mystringtokeniser.adb" 43 0 0]
                                  (([@branch_id=1059] Main.spark__branch).bool__content <-
                                     ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                        = (Standard__integer__rep.to_rep
                                             (([#"mystringtokeniser.adb" 43 0 0]
                                               (begin
                                                  ensures { true }
                                                  let _ =
                                                    let _ =
                                                      ((Mystringtokeniser__tokenise__S2b.of_array
                                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                    () in
                                                  ()
                                                end));
                                              Mystringtokeniser__tokenise__tokens.tokens__last)))));
                                 (([@branch_id=1059] Main.spark__branch).bool__content)) then
                               ([@GP_Sloc:mystringtokeniser.adb:44:16]
                                [#"mystringtokeniser.adb" 44 0 0]
                                [#"mystringtokeniser.adb" 44 0 0]
                                ((raise Return__exc) : unit))
                             else
                               (([@GP_Sloc:mystringtokeniser.adb:46:16]
                                 [#"mystringtokeniser.adb" 46 0 0] ());
                                ([@GP_Sloc:mystringtokeniser.adb:46:28]
                                 [#"mystringtokeniser.adb" 46 0 0] ());
                                ([@GP_Sloc:mystringtokeniser.adb:46:25]
                                 [#"mystringtokeniser.adb" 46 0 0]
                                 [#"mystringtokeniser.adb" 46 0 0]
                                 (Mystringtokeniser__tokenise__outindex.outindex.int__content <-
                                    ([#"mystringtokeniser.adb" 46 0 0]
                                     [@GP_Id:11]
                                     [@vc:annotation]
                                     [@GP_Sloc:mystringtokeniser.adb:46:37]
                                     [@GP_Reason:VC_OVERFLOW_CHECK]
                                     [@GP_Shape:L_1_while__if__if__outindex_assign__add]
                                     [@comment:               OutIndex := OutIndex + 1;                                     ^ mystringtokeniser.adb:46:37:VC_OVERFLOW_CHECK]
                                     (Standard__integer.range_check_
                                        ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                           + (1 : int)))))))));
                           ([@GP_Sloc:mystringtokeniser.adb:50:25]
                            [#"mystringtokeniser.adb" 50 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:50:41]
                            [#"mystringtokeniser.adb" 50 0 0] ());
                           ([@GP_Sloc:mystringtokeniser.adb:50:13]
                            [#"mystringtokeniser.adb" 50 0 0]
                            (if (([#"mystringtokeniser.adb" 50 0 0]
                                  [#"mystringtokeniser.adb" 50 0 0]
                                  (([@branch_id=1071] Main.spark__branch).bool__content <-
                                     (([#"mystringtokeniser.adb" 50 0 0]
                                       [@GP_Id:13]
                                       [@vc:annotation]
                                       [@GP_Reason:VC_OVERFLOW_CHECK]
                                       [@GP_Sloc:mystringtokeniser.adb:50:23]
                                       [@GP_Shape:L_1_while__if__if__cmp__sub]
                                       [@comment:            if S'Last - Extent.Length < Index then                       ^ mystringtokeniser.adb:50:23:VC_OVERFLOW_CHECK]
                                       (Standard__integer.range_check_
                                          ((([#"mystringtokeniser.adb" 50 0 0]
                                             ());
                                            (Standard__string.last
                                               Mystringtokeniser__tokenise__s.s))
                                             - (Standard__natural__rep.to_rep
                                                  ((Mystringtokeniser__tokenextent.__split_fields
                                                       { Mystringtokeniser__tokenextent.__split_fields =
                                                           (Mystringtokeniser__tokenextent.__split_fields__content
                                                               Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                     Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))
                                        < (Mystringtokeniser__tokenise__index.index.int__content))));
                                 (([@branch_id=1071] Main.spark__branch).bool__content)) then
                               ([@GP_Sloc:mystringtokeniser.adb:51:16]
                                [#"mystringtokeniser.adb" 51 0 0]
                                [#"mystringtokeniser.adb" 51 0 0]
                                ((raise Return__exc) : unit))
                             else
                               (([@GP_Sloc:mystringtokeniser.adb:53:16]
                                 [#"mystringtokeniser.adb" 53 0 0] ());
                                ([@GP_Sloc:mystringtokeniser.adb:53:25]
                                 [#"mystringtokeniser.adb" 53 0 0] ());
                                ([@GP_Sloc:mystringtokeniser.adb:53:33]
                                 [#"mystringtokeniser.adb" 53 0 0] ());
                                ([@GP_Sloc:mystringtokeniser.adb:53:22]
                                 [#"mystringtokeniser.adb" 53 0 0]
                                 [#"mystringtokeniser.adb" 53 0 0]
                                 (Mystringtokeniser__tokenise__index.index.int__content <-
                                    ([#"mystringtokeniser.adb" 53 0 0]
                                     [@GP_Shape:L_1_while__if__if__index_assign__add]
                                     [@GP_Id:12]
                                     [@GP_Sloc:mystringtokeniser.adb:53:31]
                                     [@vc:annotation]
                                     [@comment:               Index := Index + Extent.Length;                               ^ mystringtokeniser.adb:53:31:VC_OVERFLOW_CHECK]
                                     [@GP_Reason:VC_OVERFLOW_CHECK]
                                     (Standard__integer.range_check_
                                        ((Mystringtokeniser__tokenise__index.index.int__content)
                                           + (Standard__natural__rep.to_rep
                                                ((Mystringtokeniser__tokenextent.__split_fields
                                                     { Mystringtokeniser__tokenextent.__split_fields =
                                                         (Mystringtokeniser__tokenextent.__split_fields__content
                                                             Mystringtokeniser__tokenise__extent.extent__split_fields) }).
                                                   Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length)))))))))))
                        else ()));
                      ([@GNAT-comment:Check for the exit condition and loop statements appearing before the loop invariant of loop mystringtokeniser.adb:16]
                       ());
                      (if (not ((Boolean.andb
                                   ((Boolean.andb
                                       ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                          <= (Standard__integer__rep.to_rep
                                                ((begin
                                                    ensures { true }
                                                    let _ =
                                                      let _ =
                                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                           (Standard__integer__rep.to_rep
                                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                                          (Standard__integer__rep.to_rep
                                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                      () in
                                                    ()
                                                  end);
                                                 Mystringtokeniser__tokenise__tokens.tokens__last))))
                                      ((Mystringtokeniser__tokenise__index.index.int__content)
                                         <= (Standard__string.last
                                               Mystringtokeniser__tokenise__s.s))))
                                  ((Mystringtokeniser__tokenise__count.count.int__content)
                                     < ([#"mystringtokeniser.adb" 16 0 0]
                                        [@GP_Shape:L_1_while__and__cmp__typeconv__length_ref]
                                        [@comment:      while OutIndex <= Tokens'Last and Index <= S'Last and Count < Tokens'Length loop                                                                           ^ mystringtokeniser.adb:16:75:VC_RANGE_CHECK]
                                        [@GP_Sloc:mystringtokeniser.adb:16:75]
                                        [@vc:annotation]
                                        [@GP_Reason:VC_RANGE_CHECK]
                                        [@GP_Id:24]
                                        (Standard__integer.range_check_
                                           (([#"mystringtokeniser.adb" 16 0 0]
                                             (begin
                                                ensures { true }
                                                let _ =
                                                  let _ =
                                                    ((Mystringtokeniser__tokenise__S2b.of_array
                                                        (Mystringtokeniser__tokenise__tokens.tokens.
                                                           Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                       (Standard__integer__rep.to_rep
                                                          Mystringtokeniser__tokenise__tokens.tokens__first))
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                  () in
                                                ()
                                              end));
                                            ((Integer.length
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                               (Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__last)))))))) then
                         (raise Mystringtokeniser__tokenise__L_1.L_1)
                       else ())));
                    ([@GNAT-comment:gnat_ast_to_ptree: code before the loop invariant]
                     (([@GNAT-comment:Check for absence of RTE in the loop invariant and variant]
                       ());
                      (let temp___inv_236 =
                         (let j = val _f : int in
                                  _f in
                          if ((Boolean.andb
                                 ((Standard__integer__rep.to_rep
                                     ((begin
                                         ensures { true }
                                         let _ =
                                           let _ =
                                             ((Mystringtokeniser__tokenise__S2b.of_array
                                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                               (Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__last) in
                                           () in
                                         ()
                                       end);
                                      Mystringtokeniser__tokenise__tokens.tokens__first))
                                    <= j))
                                (j
                                   <= ([#"mystringtokeniser.adb" 18 0 0]
                                       [@GP_Id:17]
                                       [@comment:           (for all J in Tokens'First..OutIndex-1 =>                                                ^ mystringtokeniser.adb:18:48:VC_OVERFLOW_CHECK]
                                       [@vc:annotation]
                                       [@GP_Reason:VC_OVERFLOW_CHECK]
                                       [@GP_Shape:L_1_while__pragargs__forall__range__sub]
                                       [@GP_Sloc:mystringtokeniser.adb:18:48]
                                       (Standard__integer.range_check_
                                          ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                             - (1 : int)))))) then
                            (begin
                               ensures { true }
                               let _ =
                                 let _ =
                                   ((Boolean.andb
                                       ((Standard__positive__rep.to_rep
                                           ((Mystringtokeniser__tokenextent.__split_fields
                                                (let temp___237 =
                                                   ((Mystringtokeniser__tokenise__S2b.of_array
                                                       (Mystringtokeniser__tokenise__tokens.tokens.
                                                          Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__first))
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                 (Array__Int__Mystringtokeniser__tokenextent.get
                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                       temp___237))
                                                   (assert {
                                                      [#"mystringtokeniser.adb" 19 0 0]
                                                      [@GP_Id:18]
                                                      [@comment:              (Tokens(J).Start >= S'First and                       ^ mystringtokeniser.adb:19:23:VC_INDEX_CHECK]
                                                      [@vc:annotation]
                                                      [@GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                      [@GP_Sloc:mystringtokeniser.adb:19:23]
                                                      [@GP_Reason:VC_INDEX_CHECK]
                                                      (((Mystringtokeniser__tokenise__S2b.first
                                                           temp___237)
                                                          <= j) /\
                                                         (j
                                                            <= (Mystringtokeniser__tokenise__S2b.last
                                                                  temp___237))) };
                                                    j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                          >= (Standard__string.first
                                                Mystringtokeniser__tokenise__s.s)))
                                      ((Standard__natural__rep.to_rep
                                          ((Mystringtokeniser__tokenextent.__split_fields
                                               (let temp___238 =
                                                  ((Mystringtokeniser__tokenise__S2b.of_array
                                                      (Mystringtokeniser__tokenise__tokens.tokens.
                                                         Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__first))
                                                    (Standard__integer__rep.to_rep
                                                       Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                (Array__Int__Mystringtokeniser__tokenextent.get
                                                   (Mystringtokeniser__tokenise__S2b.to_array
                                                      temp___238))
                                                  (assert {
                                                     [#"mystringtokeniser.adb" 20 0 0]
                                                     [@GP_Id:19]
                                                     [@comment:                   Tokens(J).Length > 0) and then                           ^ mystringtokeniser.adb:20:27:VC_INDEX_CHECK]
                                                     [@GP_Sloc:mystringtokeniser.adb:20:27]
                                                     [@vc:annotation]
                                                     [@GP_Shape:L_1_while__pragargs__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                                     [@GP_Reason:VC_INDEX_CHECK]
                                                     (((Mystringtokeniser__tokenise__S2b.first
                                                          temp___238)
                                                         <= j) /\
                                                        (j
                                                           <= (Mystringtokeniser__tokenise__S2b.last
                                                                 temp___238))) };
                                                   j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                         > (0 : int)))
                                    &&
                                     (((Standard__natural__rep.to_rep
                                          ((Mystringtokeniser__tokenextent.__split_fields
                                               (let temp___239 =
                                                  ((Mystringtokeniser__tokenise__S2b.of_array
                                                      (Mystringtokeniser__tokenise__tokens.tokens.
                                                         Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                     (Standard__integer__rep.to_rep
                                                        Mystringtokeniser__tokenise__tokens.tokens__first))
                                                    (Standard__integer__rep.to_rep
                                                       Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                (Array__Int__Mystringtokeniser__tokenextent.get
                                                   (Mystringtokeniser__tokenise__S2b.to_array
                                                      temp___239))
                                                  (assert {
                                                     [#"mystringtokeniser.adb" 21 0 0]
                                                     [@vc:annotation]
                                                     [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                    ^ mystringtokeniser.adb:21:20:VC_INDEX_CHECK]
                                                     [@GP_Sloc:mystringtokeniser.adb:21:20]
                                                     [@GP_Reason:VC_INDEX_CHECK]
                                                     [@GP_Id:20]
                                                     [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                                     (((Mystringtokeniser__tokenise__S2b.first
                                                          temp___239)
                                                         <= j) /\
                                                        (j
                                                           <= (Mystringtokeniser__tokenise__S2b.last
                                                                 temp___239))) };
                                                   j))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                         - (1 : int))
                                        <= ([#"mystringtokeniser.adb" 21 0 0]
                                            [@GP_Sloc:mystringtokeniser.adb:21:42]
                                            [@vc:annotation]
                                            [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                          ^ mystringtokeniser.adb:21:42:VC_OVERFLOW_CHECK]
                                            [@GP_Reason:VC_OVERFLOW_CHECK]
                                            [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub]
                                            [@GP_Id:22]
                                            (Standard__integer.range_check_
                                               ((([#"mystringtokeniser.adb" 21 0 0]
                                                  ());
                                                 (Standard__string.last
                                                    Mystringtokeniser__tokenise__s.s))
                                                  - (Standard__positive__rep.to_rep
                                                       ((Mystringtokeniser__tokenextent.__split_fields
                                                            (let temp___240 =
                                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                  (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                                   temp___240))
                                                               (([#"mystringtokeniser.adb" 21 0 0]
                                                                 assert {
                                                                   [#"mystringtokeniser.adb" 21 0 0]
                                                                   [#"mystringtokeniser.adb" 21 0 0]
                                                                   [@comment:            Tokens(J).Length-1 <= S'Last - Tokens(J).Start);                                                   ^ mystringtokeniser.adb:21:51:VC_INDEX_CHECK]
                                                                   [@vc:annotation]
                                                                   [@GP_Reason:VC_INDEX_CHECK]
                                                                   [@GP_Sloc:mystringtokeniser.adb:21:51]
                                                                   [@GP_Id:21]
                                                                   [@GP_Shape:L_1_while__pragargs__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                                                   (((Mystringtokeniser__tokenise__S2b.first
                                                                    temp___240)
                                                                    <= j) /\
                                                                    (j
                                                                    <= (Mystringtokeniser__tokenise__S2b.last
                                                                    temp___240))) });
                                                                j))).
                                                          Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))) in
                                 () in
                               ()
                             end)
                          else ());
                         (val _f : bool
                            ensures { ((result = True) <->
                                         (forall j : int.
                                            ((((Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__first)
                                                 <= j) /\
                                                (j
                                                   <= ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                                         - (1 : int)))) ->
                                               ((((Standard__positive__rep.to_rep
                                                     ((Mystringtokeniser__tokenextent.__split_fields
                                                          (let temp___241 =
                                                             ((Mystringtokeniser__tokenise__S2b.of_array
                                                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                (Standard__integer__rep.to_rep
                                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                                               (Standard__integer__rep.to_rep
                                                                  Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                           (Array__Int__Mystringtokeniser__tokenextent.get
                                                              (Mystringtokeniser__tokenise__S2b.to_array
                                                                 temp___241))
                                                             j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                                    >= (Standard__string.first
                                                          Mystringtokeniser__tokenise__s.s)) /\
                                                   ((Standard__natural__rep.to_rep
                                                       ((Mystringtokeniser__tokenextent.__split_fields
                                                            (let temp___242 =
                                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                  (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                                   temp___242))
                                                               j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                      > (0 : int))) /\
                                                  (((Standard__natural__rep.to_rep
                                                       ((Mystringtokeniser__tokenextent.__split_fields
                                                            (let temp___243 =
                                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                  (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                                   temp___243))
                                                               j)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                                      - (1 : int))
                                                     <= ((Standard__string.last
                                                            Mystringtokeniser__tokenise__s.s)
                                                           - (Standard__positive__rep.to_rep
                                                                ((Mystringtokeniser__tokenextent.__split_fields
                                                                    (let temp___244 =
                                                                    ((Mystringtokeniser__tokenise__S2b.of_array
                                                                    (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                    (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                                    (Array__Int__Mystringtokeniser__tokenextent.get
                                                                    (Mystringtokeniser__tokenise__S2b.to_array
                                                                    temp___244))
                                                                    j)).
                                                                   Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))))) } in
                          _f) in
                       begin
                         ensures { true }
                         let _ =
                           let _ =
                             let temp___inv_235 =
                               ((Mystringtokeniser__tokenise__outindex.outindex.int__content)
                                  = ([#"mystringtokeniser.adb" 23 0 0]
                                     [@comment:         pragma Loop_Invariant (OutIndex = Tokens'First + Count);                                                         ^ mystringtokeniser.adb:23:57:VC_OVERFLOW_CHECK]
                                     [@GP_Id:15]
                                     [@GP_Shape:L_1_while__pragargs__cmp__add]
                                     [@vc:annotation]
                                     [@GP_Reason:VC_OVERFLOW_CHECK]
                                     [@GP_Sloc:mystringtokeniser.adb:23:57]
                                     (Standard__integer.range_check_
                                        ((Standard__integer__rep.to_rep
                                            (([#"mystringtokeniser.adb" 23 0 0]
                                              (begin
                                                 ensures { true }
                                                 let _ =
                                                   let _ =
                                                     ((Mystringtokeniser__tokenise__S2b.of_array
                                                         (Mystringtokeniser__tokenise__tokens.tokens.
                                                            Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__first))
                                                       (Standard__integer__rep.to_rep
                                                          Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                   () in
                                                 ()
                                               end));
                                             Mystringtokeniser__tokenise__tokens.tokens__first))
                                           + (Mystringtokeniser__tokenise__count.count.int__content))))) in
                             () in
                           () in
                         ()
                       end)));
                    ([@GNAT-comment:gnat_ast_to_ptree: code checking the variants]
                     ())
                  done))
              with Mystringtokeniser__tokenise__L_1.L_1 -> ()
              end)
           else ())));
        (raise Return__exc)
      with Return__exc -> ()
      end);
     (begin
        ensures { true }
        let _ =
          let _ =
            (Boolean.andb
               ((Mystringtokeniser__tokenise__count.count.int__content)
                  <= ([#"mystringtokeniser.ads" 18 0 0]
                      [@GP_Shape:pragargs__and__cmp__typeconv__length_ref]
                      [@GP_Sloc:mystringtokeniser.ads:18:29]
                      [@vc:annotation]
                      [@comment:     Post => Count <= Tokens'Length and                             ^ mystringtokeniser.ads:18:29:VC_RANGE_CHECK]
                      [@GP_Reason:VC_RANGE_CHECK]
                      [@GP_Id:25]
                      (Standard__integer.range_check_
                         (([#"mystringtokeniser.ads" 18 0 0]
                           (begin
                              ensures { true }
                              let _ =
                                let _ =
                                  ((Mystringtokeniser__tokenise__S2b.of_array
                                      (Mystringtokeniser__tokenise__tokens.tokens.
                                         Array__Int__Mystringtokeniser__tokenextent.map__content))
                                     (Standard__integer__rep.to_rep
                                        Mystringtokeniser__tokenise__tokens.tokens__first))
                                    (Standard__integer__rep.to_rep
                                       Mystringtokeniser__tokenise__tokens.tokens__last) in
                                () in
                              ()
                            end));
                          ((Integer.length
                              (Standard__integer__rep.to_rep
                                 Mystringtokeniser__tokenise__tokens.tokens__first))
                             (Standard__integer__rep.to_rep
                                Mystringtokeniser__tokenise__tokens.tokens__last)))))))
              ((let index = val _f : int in
                            _f in
                if ((Boolean.andb
                       ((Standard__integer__rep.to_rep
                           ((begin
                               ensures { true }
                               let _ =
                                 let _ =
                                   ((Mystringtokeniser__tokenise__S2b.of_array
                                       (Mystringtokeniser__tokenise__tokens.tokens.
                                          Array__Int__Mystringtokeniser__tokenextent.map__content))
                                      (Standard__integer__rep.to_rep
                                         Mystringtokeniser__tokenise__tokens.tokens__first))
                                     (Standard__integer__rep.to_rep
                                        Mystringtokeniser__tokenise__tokens.tokens__last) in
                                 () in
                               ()
                             end);
                            Mystringtokeniser__tokenise__tokens.tokens__first))
                          <= index))
                      (index
                         <= ([#"mystringtokeniser.ads" 19 0 0]
                             [@GP_Shape:pragargs__and__forall__range__add]
                             [@vc:annotation]
                             [@GP_Reason:VC_OVERFLOW_CHECK]
                             [@comment:     (for all Index in Tokens'First..Tokens'First+(Count-1) =>                                                  ^ mystringtokeniser.ads:19:50:VC_OVERFLOW_CHECK]
                             [@GP_Sloc:mystringtokeniser.ads:19:50]
                             [@GP_Id:26]
                             (Standard__integer.range_check_
                                ((Standard__integer__rep.to_rep
                                    (([#"mystringtokeniser.ads" 19 0 0]
                                      (begin
                                         ensures { true }
                                         let _ =
                                           let _ =
                                             ((Mystringtokeniser__tokenise__S2b.of_array
                                                 (Mystringtokeniser__tokenise__tokens.tokens.
                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                (Standard__integer__rep.to_rep
                                                   Mystringtokeniser__tokenise__tokens.tokens__first))
                                               (Standard__integer__rep.to_rep
                                                  Mystringtokeniser__tokenise__tokens.tokens__last) in
                                           () in
                                         ()
                                       end));
                                     Mystringtokeniser__tokenise__tokens.tokens__first))
                                   + ((Mystringtokeniser__tokenise__count.count.int__content)
                                        - (1 : int))))))) then
                  (begin
                     ensures { true }
                     let _ =
                       let _ =
                         ((Boolean.andb
                             ((Standard__positive__rep.to_rep
                                 ((Mystringtokeniser__tokenextent.__split_fields
                                      (let temp___250 =
                                         ((Mystringtokeniser__tokenise__S2b.of_array
                                             (Mystringtokeniser__tokenise__tokens.tokens.
                                                Array__Int__Mystringtokeniser__tokenextent.map__content))
                                            (Standard__integer__rep.to_rep
                                               Mystringtokeniser__tokenise__tokens.tokens__first))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__last) in
                                       (Array__Int__Mystringtokeniser__tokenextent.get
                                          (Mystringtokeniser__tokenise__S2b.to_array
                                             temp___250))
                                         (assert {
                                            [#"mystringtokeniser.ads" 20 0 0]
                                            [@comment:          (Tokens(Index).Start >= S'First and                   ^ mystringtokeniser.ads:20:19:VC_INDEX_CHECK]
                                            [@vc:annotation]
                                            [@GP_Sloc:mystringtokeniser.ads:20:19]
                                            [@GP_Shape:pragargs__and__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                            [@GP_Reason:VC_INDEX_CHECK]
                                            [@GP_Id:27]
                                            (((Mystringtokeniser__tokenise__S2b.first
                                                 temp___250)
                                                <= index) /\
                                               (index
                                                  <= (Mystringtokeniser__tokenise__S2b.last
                                                        temp___250))) };
                                          index))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                >= (Standard__string.first
                                      Mystringtokeniser__tokenise__s.s)))
                            ((Standard__natural__rep.to_rep
                                ((Mystringtokeniser__tokenextent.__split_fields
                                     (let temp___251 =
                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                      (Array__Int__Mystringtokeniser__tokenextent.get
                                         (Mystringtokeniser__tokenise__S2b.to_array
                                            temp___251))
                                        (assert {
                                           [#"mystringtokeniser.ads" 21 0 0]
                                           [@vc:annotation]
                                           [@GP_Shape:pragargs__and__forall__andthen__and__cmp__selectcomp__ixdcomp]
                                           [@comment:          Tokens(Index).Length > 0) and then                  ^ mystringtokeniser.ads:21:18:VC_INDEX_CHECK]
                                           [@GP_Reason:VC_INDEX_CHECK]
                                           [@GP_Sloc:mystringtokeniser.ads:21:18]
                                           [@GP_Id:28]
                                           (((Mystringtokeniser__tokenise__S2b.first
                                                temp___251)
                                               <= index) /\
                                              (index
                                                 <= (Mystringtokeniser__tokenise__S2b.last
                                                       temp___251))) };
                                         index))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                               > (0 : int)))
                          &&
                           (((Standard__natural__rep.to_rep
                                ((Mystringtokeniser__tokenextent.__split_fields
                                     (let temp___252 =
                                        ((Mystringtokeniser__tokenise__S2b.of_array
                                            (Mystringtokeniser__tokenise__tokens.tokens.
                                               Array__Int__Mystringtokeniser__tokenextent.map__content))
                                           (Standard__integer__rep.to_rep
                                              Mystringtokeniser__tokenise__tokens.tokens__first))
                                          (Standard__integer__rep.to_rep
                                             Mystringtokeniser__tokenise__tokens.tokens__last) in
                                      (Array__Int__Mystringtokeniser__tokenextent.get
                                         (Mystringtokeniser__tokenise__S2b.to_array
                                            temp___252))
                                        (assert {
                                           [#"mystringtokeniser.ads" 22 0 0]
                                           [@vc:annotation]
                                           [@GP_Sloc:mystringtokeniser.ads:22:20]
                                           [@GP_Reason:VC_INDEX_CHECK]
                                           [@comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);                    ^ mystringtokeniser.ads:22:20:VC_INDEX_CHECK]
                                           [@GP_Id:29]
                                           [@GP_Shape:pragargs__and__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                           (((Mystringtokeniser__tokenise__S2b.first
                                                temp___252)
                                               <= index) /\
                                              (index
                                                 <= (Mystringtokeniser__tokenise__S2b.last
                                                       temp___252))) };
                                         index))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                               - (1 : int))
                              <= ([#"mystringtokeniser.ads" 22 0 0]
                                  [@GP_Sloc:mystringtokeniser.ads:22:46]
                                  [@vc:annotation]
                                  [@GP_Reason:VC_OVERFLOW_CHECK]
                                  [@GP_Id:31]
                                  [@GP_Shape:pragargs__and__forall__andthen__cmp__sub]
                                  [@comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);                                              ^ mystringtokeniser.ads:22:46:VC_OVERFLOW_CHECK]
                                  (Standard__integer.range_check_
                                     ((([#"mystringtokeniser.ads" 22 0 0] ());
                                       (Standard__string.last
                                          Mystringtokeniser__tokenise__s.s))
                                        - (Standard__positive__rep.to_rep
                                             ((Mystringtokeniser__tokenextent.__split_fields
                                                  (let temp___253 =
                                                     ((Mystringtokeniser__tokenise__S2b.of_array
                                                         (Mystringtokeniser__tokenise__tokens.tokens.
                                                            Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__first))
                                                       (Standard__integer__rep.to_rep
                                                          Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                   (Array__Int__Mystringtokeniser__tokenextent.get
                                                      (Mystringtokeniser__tokenise__S2b.to_array
                                                         temp___253))
                                                     (([#"mystringtokeniser.ads" 22 0 0]
                                                       assert {
                                                         [#"mystringtokeniser.ads" 22 0 0]
                                                         [#"mystringtokeniser.ads" 22 0 0]
                                                         [@vc:annotation]
                                                         [@GP_Id:30]
                                                         [@comment:            Tokens(Index).Length-1 <= S'Last - Tokens(Index).Start);                                                       ^ mystringtokeniser.ads:22:55:VC_INDEX_CHECK]
                                                         [@GP_Reason:VC_INDEX_CHECK]
                                                         [@GP_Sloc:mystringtokeniser.ads:22:55]
                                                         [@GP_Shape:pragargs__and__forall__andthen__cmp__sub__selectcomp__ixdcomp]
                                                         (((Mystringtokeniser__tokenise__S2b.first
                                                              temp___253)
                                                             <= index) /\
                                                            (index
                                                               <= (Mystringtokeniser__tokenise__S2b.last
                                                                    temp___253))) });
                                                      index))).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start)))))) in
                       () in
                     ()
                   end)
                else ());
               (val _f : bool
                  ensures { ((result = True) <->
                               (forall index : int.
                                  ((((Standard__integer__rep.to_rep
                                        Mystringtokeniser__tokenise__tokens.tokens__first)
                                       <= index) /\
                                      (index
                                         <= ((Standard__integer__rep.to_rep
                                                Mystringtokeniser__tokenise__tokens.tokens__first)
                                               + ((Mystringtokeniser__tokenise__count.count.int__content)
                                                    - (1 : int))))) ->
                                     ((([@GP_Pretty_Ada:1233]
                                        ((Standard__positive__rep.to_rep
                                            ((Mystringtokeniser__tokenextent.__split_fields
                                                 (let temp___254 =
                                                    ((Mystringtokeniser__tokenise__S2b.of_array
                                                        (Mystringtokeniser__tokenise__tokens.tokens.
                                                           Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                       (Standard__integer__rep.to_rep
                                                          Mystringtokeniser__tokenise__tokens.tokens__first))
                                                      (Standard__integer__rep.to_rep
                                                         Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                  (Array__Int__Mystringtokeniser__tokenextent.get
                                                     (Mystringtokeniser__tokenise__S2b.to_array
                                                        temp___254))
                                                    index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))
                                           >= (Standard__string.first
                                                 Mystringtokeniser__tokenise__s.s))) /\
                                         ([@GP_Pretty_Ada:1243]
                                          ((Standard__natural__rep.to_rep
                                              ((Mystringtokeniser__tokenextent.__split_fields
                                                   (let temp___255 =
                                                      ((Mystringtokeniser__tokenise__S2b.of_array
                                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                    (Array__Int__Mystringtokeniser__tokenextent.get
                                                       (Mystringtokeniser__tokenise__S2b.to_array
                                                          temp___255))
                                                      index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                             > (0 : int)))) /\
                                        ([@GP_Pretty_Ada:1253]
                                         (((Standard__natural__rep.to_rep
                                              ((Mystringtokeniser__tokenextent.__split_fields
                                                   (let temp___256 =
                                                      ((Mystringtokeniser__tokenise__S2b.of_array
                                                          (Mystringtokeniser__tokenise__tokens.tokens.
                                                             Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                         (Standard__integer__rep.to_rep
                                                            Mystringtokeniser__tokenise__tokens.tokens__first))
                                                        (Standard__integer__rep.to_rep
                                                           Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                    (Array__Int__Mystringtokeniser__tokenextent.get
                                                       (Mystringtokeniser__tokenise__S2b.to_array
                                                          temp___256))
                                                      index)).Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__length))
                                             - (1 : int))
                                            <= ((Standard__string.last
                                                   Mystringtokeniser__tokenise__s.s)
                                                  - (Standard__positive__rep.to_rep
                                                       ((Mystringtokeniser__tokenextent.__split_fields
                                                            (let temp___257 =
                                                               ((Mystringtokeniser__tokenise__S2b.of_array
                                                                   (Mystringtokeniser__tokenise__tokens.tokens.
                                                                    Array__Int__Mystringtokeniser__tokenextent.map__content))
                                                                  (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__first))
                                                                 (Standard__integer__rep.to_rep
                                                                    Mystringtokeniser__tokenise__tokens.tokens__last) in
                                                             (Array__Int__Mystringtokeniser__tokenextent.get
                                                                (Mystringtokeniser__tokenise__S2b.to_array
                                                                   temp___257))
                                                               index)).
                                                          Mystringtokeniser__tokenextent.rec__mystringtokeniser__tokenextent__start))))))))) } in
                _f)) in
          () in
        ()
      end))
end
